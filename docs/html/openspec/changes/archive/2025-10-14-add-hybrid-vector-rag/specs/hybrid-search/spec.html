

<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="../../../../../../">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>ADDED Requirements &mdash; DocsToKG 1.0.0 documentation</title>
      <link rel="stylesheet" type="text/css" href="../../../../../../_static/pygments.css?v=b86133f3" />
      <link rel="stylesheet" type="text/css" href="../../../../../../_static/css/theme.css?v=e59714d7" />
      <link rel="stylesheet" type="text/css" href="../../../../../../_static/css/custom.css" />

  
      <script src="../../../../../../_static/jquery.js?v=5d32c60e"></script>
      <script src="../../../../../../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
      <script src="../../../../../../_static/documentation_options.js?v=8d563738"></script>
      <script src="../../../../../../_static/doctools.js?v=9bcbadda"></script>
      <script src="../../../../../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../../../../../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../../../../../genindex.html" />
    <link rel="search" title="Search" href="../../../../../../search.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../../../../../../index.html" class="icon icon-home">
            DocsToKG
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../../../01-overview/index.html">1. Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../../02-setup/index.html">1. Setup Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../../03-architecture/index.html">1. Architecture Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../../04-api/index.html">1. API Reference</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../../05-development/index.html">1. Development Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../../06-operations/index.html">1. Operations Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../../07-reference/index.html">1. Technical Reference</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../../../../index.html">DocsToKG</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../../../../../index.html" class="icon icon-home" aria-label="Home"></a></li>
      <li class="breadcrumb-item active">ADDED Requirements</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../../../../../../_sources/openspec/changes/archive/2025-10-14-add-hybrid-vector-rag/specs/hybrid-search/spec.md.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="added-requirements">
<h1>ADDED Requirements<a class="headerlink" href="#added-requirements" title="Link to this heading"></a></h1>
<section id="requirement-hybrid-retrieval-storage">
<h2>Requirement: Hybrid Retrieval Storage<a class="headerlink" href="#requirement-hybrid-retrieval-storage" title="Link to this heading"></a></h2>
<p>The system SHALL persist chunk-level content in OpenSearch for sparse retrieval and in GPU FAISS indexes for dense retrieval, using a shared <code class="docutils literal notranslate"><span class="pre">vector_id</span></code> (UUID) across both systems via IndexIDMap2.</p>
<section id="scenario-ingest-chunk-into-dual-indexes">
<h3>Scenario: Ingest chunk into dual indexes<a class="headerlink" href="#scenario-ingest-chunk-into-dual-indexes" title="Link to this heading"></a></h3>
<ul class="simple">
<li><p><strong>GIVEN</strong> a chunk payload that includes doc metadata, SPLADEv3 weights, and a normalized Qwen3-4B embedding</p></li>
<li><p><strong>WHEN</strong> the upsert pipeline runs</p></li>
<li><p><strong>THEN</strong> the chunk is stored in the OpenSearch index with its metadata and sparse features</p></li>
<li><p><strong>AND</strong> the same chunk vector is inserted into the FAISS index under its <code class="docutils literal notranslate"><span class="pre">vector_id</span></code></p></li>
</ul>
</section>
</section>
<section id="requirement-chunk-schema-and-index-configuration">
<h2>Requirement: Chunk Schema and Index Configuration<a class="headerlink" href="#requirement-chunk-schema-and-index-configuration" title="Link to this heading"></a></h2>
<p>OpenSearch mappings SHALL include fields for <code class="docutils literal notranslate"><span class="pre">doc_id</span></code>, <code class="docutils literal notranslate"><span class="pre">chunk_id</span></code>, <code class="docutils literal notranslate"><span class="pre">namespace</span></code>, <code class="docutils literal notranslate"><span class="pre">text</span></code>, <code class="docutils literal notranslate"><span class="pre">splade</span></code> rank_features, <code class="docutils literal notranslate"><span class="pre">vector_id</span></code>, and filterable metadata such as <code class="docutils literal notranslate"><span class="pre">author</span></code>, <code class="docutils literal notranslate"><span class="pre">tags</span></code>, <code class="docutils literal notranslate"><span class="pre">published_at</span></code>, and ACL fields. Chunking SHALL default to 400–800 token windows with 100–200 token overlaps, configurable per corpus.</p>
<section id="scenario-bootstrap-opensearch-mappings">
<h3>Scenario: Bootstrap OpenSearch mappings<a class="headerlink" href="#scenario-bootstrap-opensearch-mappings" title="Link to this heading"></a></h3>
<ul class="simple">
<li><p><strong>GIVEN</strong> a new namespace onboarding</p></li>
<li><p><strong>WHEN</strong> the schema bootstrap routine executes</p></li>
<li><p><strong>THEN</strong> the OpenSearch index is created with the required keyword, text, rank_features, and numeric/date fields</p></li>
<li><p><strong>AND</strong> chunking parameters are recorded so ingest jobs emit overlapping windows within the specified bounds</p></li>
</ul>
</section>
</section>
<section id="requirement-chunk-processing-and-feature-generation-pipeline">
<h2>Requirement: Chunk Processing and Feature Generation Pipeline<a class="headerlink" href="#requirement-chunk-processing-and-feature-generation-pipeline" title="Link to this heading"></a></h2>
<p>The ingestion service SHALL accept raw documents, apply the configured chunker, and emit chunk payloads that include deterministic UUIDs, normalized metadata, SPLADE token/weight maps, and Qwen3-4B dense embeddings generated through approved model helpers. Failed chunk transformations SHALL surface retryable vs terminal errors distinctly and shall never emit partial chunks for a document.</p>
<section id="scenario-transform-document-into-enriched-chunks">
<h3>Scenario: Transform document into enriched chunks<a class="headerlink" href="#scenario-transform-document-into-enriched-chunks" title="Link to this heading"></a></h3>
<ul class="simple">
<li><p><strong>GIVEN</strong> a document with raw text and metadata</p></li>
<li><p><strong>WHEN</strong> the pipeline processes the document</p></li>
<li><p><strong>THEN</strong> it produces chunk records whose UUIDs remain stable across re-processing, with SPLADE/BM25 features derived from the shared tokenizer, normalized Qwen embeddings, and sanitized metadata aligned to the OpenSearch schema</p></li>
<li><p><strong>AND</strong> any failure during SPLADE or dense embedding generation marks the entire document batch for retry while logging trace context for dead-letter handling</p></li>
</ul>
</section>
</section>
<section id="requirement-configuration-and-parameter-management">
<h2>Requirement: Configuration and Parameter Management<a class="headerlink" href="#requirement-configuration-and-parameter-management" title="Link to this heading"></a></h2>
<p>The system SHALL expose configuration files or service-level configuration for choosing FAISS index type (Flat, IVF-Flat, IVFPQ), setting IVF parameters (<code class="docutils literal notranslate"><span class="pre">nlist</span></code>, <code class="docutils literal notranslate"><span class="pre">nprobe</span></code>, PQ <code class="docutils literal notranslate"><span class="pre">M</span></code>, <code class="docutils literal notranslate"><span class="pre">nbits</span></code>), chunk window sizes, oversampling ratios, fusion <code class="docutils literal notranslate"><span class="pre">k0</span></code>, MMR λ, cosine dedupe thresholds, and namespace-to-index mappings. Configuration changes SHALL be reloadable without redeploying the service.</p>
<section id="scenario-adjust-retrieval-parameters-without-outage">
<h3>Scenario: Adjust retrieval parameters without outage<a class="headerlink" href="#scenario-adjust-retrieval-parameters-without-outage" title="Link to this heading"></a></h3>
<ul class="simple">
<li><p><strong>GIVEN</strong> an operator updates the retrieval configuration to raise <code class="docutils literal notranslate"><span class="pre">nprobe</span></code> and adjust MMR λ</p></li>
<li><p><strong>WHEN</strong> the configuration reload endpoint or watcher triggers</p></li>
<li><p><strong>THEN</strong> the running service applies the new parameters to subsequent searches without downtime and persists the effective configuration for audit</p></li>
</ul>
</section>
</section>
<section id="requirement-faiss-index-provisioning">
<h2>Requirement: FAISS Index Provisioning<a class="headerlink" href="#requirement-faiss-index-provisioning" title="Link to this heading"></a></h2>
<p>The system SHALL provision GPU FAISS indexes for 2560-d embeddings using cosine similarity via L2 normalization and Inner Product metrics, supporting GpuIndexFlatIP for exact search and GpuIndexIVFFlat or GpuIndexIVFPQ for ANN with train-before-add semantics.</p>
<section id="scenario-initialize-faiss-index">
<h3>Scenario: Initialize FAISS index<a class="headerlink" href="#scenario-initialize-faiss-index" title="Link to this heading"></a></h3>
<ul class="simple">
<li><p><strong>GIVEN</strong> StandardGpuResources and configuration indicating Flat or IVF mode</p></li>
<li><p><strong>WHEN</strong> the retrieval service starts</p></li>
<li><p><strong>THEN</strong> the FAISS index is created on the target GPU, trained if IVF/PQ is selected, and wrapped in IndexIDMap2 to enforce explicit IDs</p></li>
</ul>
</section>
</section>
<section id="requirement-batch-upsert-and-delete-semantics">
<h2>Requirement: Batch Upsert and Delete Semantics<a class="headerlink" href="#requirement-batch-upsert-and-delete-semantics" title="Link to this heading"></a></h2>
<p>Upsert workflows SHALL batch vectors (e.g., 50k–100k) to control GPU memory pressure, normalize embeddings with <code class="docutils literal notranslate"><span class="pre">faiss.normalize_L2</span></code>, remove existing IDs before re-adding, and ensure deletions call both OpenSearch delete and <code class="docutils literal notranslate"><span class="pre">remove_ids</span></code> in FAISS.</p>
<section id="scenario-re-ingest-updated-chunk-batch">
<h3>Scenario: Re-ingest updated chunk batch<a class="headerlink" href="#scenario-re-ingest-updated-chunk-batch" title="Link to this heading"></a></h3>
<ul class="simple">
<li><p><strong>GIVEN</strong> an incoming batch that updates existing chunk UUIDs</p></li>
<li><p><strong>WHEN</strong> the batch upsert runs</p></li>
<li><p><strong>THEN</strong> the pipeline removes prior FAISS entries for those IDs, re-adds normalized vectors, and upserts OpenSearch documents in the same transaction scope</p></li>
<li><p><strong>AND</strong> ingest metrics record successes/failures while transactional guards prevent FAISS/OpenSearch divergence by retrying failed legs and flagging the batch for manual inspection if reconciliation fails</p></li>
</ul>
</section>
</section>
<section id="requirement-multi-channel-query-execution">
<h2>Requirement: Multi-Channel Query Execution<a class="headerlink" href="#requirement-multi-channel-query-execution" title="Link to this heading"></a></h2>
<p>For each search request, the system SHALL: (1) issue BM25 queries to OpenSearch with filter predicates and PIT + search_after pagination, (2) issue SPLADE neural sparse queries using token→weight rank_features, and (3) compute a normalized dense embedding, perform FAISS <code class="docutils literal notranslate"><span class="pre">search(k')</span></code> with oversampling for filters, and join dense hits back to metadata via <code class="docutils literal notranslate"><span class="pre">vector_id</span></code>.</p>
<section id="scenario-execute-hybrid-search-request">
<h3>Scenario: Execute hybrid search request<a class="headerlink" href="#scenario-execute-hybrid-search-request" title="Link to this heading"></a></h3>
<ul class="simple">
<li><p><strong>GIVEN</strong> a user query with namespace and tag filters</p></li>
<li><p><strong>WHEN</strong> the retrieval service processes the request</p></li>
<li><p><strong>THEN</strong> BM25, SPLADE, and dense searches run in parallel or pipelined fashion, each respecting the filters (dense via post-filter on joined metadata)</p></li>
<li><p><strong>AND</strong> the dense search oversamples results before post-filtering to retain at least <code class="docutils literal notranslate"><span class="pre">k</span></code> matches per namespace constraint</p></li>
</ul>
</section>
</section>
<section id="requirement-query-service-contract">
<h2>Requirement: Query Service Contract<a class="headerlink" href="#requirement-query-service-contract" title="Link to this heading"></a></h2>
<p>The retrieval service SHALL expose a synchronous API (<code class="docutils literal notranslate"><span class="pre">POST</span> <span class="pre">/v1/hybrid-search</span></code>) that accepts the query text, optional namespace/metadata filters, pagination cursor, flags for diversification, and desired result count. The response SHALL include fused results with per-channel diagnostics (scores, ranks) and cursors for subsequent pages.</p>
<section id="scenario-invoke-hybrid-search-endpoint">
<h3>Scenario: Invoke hybrid search endpoint<a class="headerlink" href="#scenario-invoke-hybrid-search-endpoint" title="Link to this heading"></a></h3>
<ul class="simple">
<li><p><strong>GIVEN</strong> a client sends a JSON body containing <code class="docutils literal notranslate"><span class="pre">query</span></code>, <code class="docutils literal notranslate"><span class="pre">namespace</span></code>, <code class="docutils literal notranslate"><span class="pre">filters</span></code>, <code class="docutils literal notranslate"><span class="pre">page_size</span></code>, and <code class="docutils literal notranslate"><span class="pre">cursor</span></code></p></li>
<li><p><strong>WHEN</strong> the service completes BM25/SPLADE/dense searches and fusion</p></li>
<li><p><strong>THEN</strong> it returns HTTP 200 with a payload that lists fused results (with doc/chunk IDs, highlight spans, scores by channel, and citations), alongside a <code class="docutils literal notranslate"><span class="pre">next_cursor</span></code> when more results exist and timing metadata for observability</p></li>
</ul>
</section>
</section>
<section id="requirement-hybrid-fusion-and-diversification">
<h2>Requirement: Hybrid Fusion and Diversification<a class="headerlink" href="#requirement-hybrid-fusion-and-diversification" title="Link to this heading"></a></h2>
<p>The system SHALL combine BM25, SPLADE, and dense candidate lists using Reciprocal Rank Fusion with configurable <code class="docutils literal notranslate"><span class="pre">k0</span></code> (default 60) and support optional score normalization. When diversification is enabled, it SHALL apply MMR with λ∈[0.5,0.8] over the top-M fused set before emitting the top-K results.</p>
<section id="scenario-fuse-retrieval-channels-with-mmr">
<h3>Scenario: Fuse retrieval channels with MMR<a class="headerlink" href="#scenario-fuse-retrieval-channels-with-mmr" title="Link to this heading"></a></h3>
<ul class="simple">
<li><p><strong>GIVEN</strong> candidate lists from BM25, SPLADE, and dense searches</p></li>
<li><p><strong>WHEN</strong> the caller enables diversification</p></li>
<li><p><strong>THEN</strong> RRF produces fused scores</p></li>
<li><p><strong>AND</strong> MMR prunes the fused list so the final top-K balances relevance and cosine-based novelty within configured λ bounds</p></li>
</ul>
</section>
</section>
<section id="requirement-result-shaping-for-rag-responses">
<h2>Requirement: Result Shaping for RAG Responses<a class="headerlink" href="#requirement-result-shaping-for-rag-responses" title="Link to this heading"></a></h2>
<p>Result shaping SHALL collapse hits by <code class="docutils literal notranslate"><span class="pre">doc_id</span></code> (configurable chunks per doc), dedupe near-duplicates by dense cosine ≥0.98 or shared fingerprints, request OpenSearch highlights for BM25/SPLADE matches, provide fallback snippets for dense-only hits, and assemble context blocks with citation metadata and token budgets.</p>
<section id="scenario-assemble-rag-context-package">
<h3>Scenario: Assemble RAG context package<a class="headerlink" href="#scenario-assemble-rag-context-package" title="Link to this heading"></a></h3>
<ul class="simple">
<li><p><strong>GIVEN</strong> fused hybrid hits that include multiple chunks of the same document</p></li>
<li><p><strong>WHEN</strong> result shaping runs</p></li>
<li><p><strong>THEN</strong> the response collapses duplicate doc_ids to the configured limit, removes high-similarity duplicates, and returns highlight-rich context blocks with citations and remaining token budget</p></li>
<li><p><strong>AND</strong> the service annotates each context block with channel contributions, snippet provenance offsets, and token counts so downstream RAG components can budget prompts</p></li>
</ul>
</section>
</section>
<section id="requirement-namespace-isolation-and-filtering">
<h2>Requirement: Namespace Isolation and Filtering<a class="headerlink" href="#requirement-namespace-isolation-and-filtering" title="Link to this heading"></a></h2>
<p>Namespaces SHALL be represented as keyword fields in OpenSearch documents and carried through to FAISS results via <code class="docutils literal notranslate"><span class="pre">vector_id</span></code> joins. The system SHALL support both single shared FAISS indexes with downstream filtering and per-namespace FAISS indexes when isolation is required.</p>
<section id="scenario-apply-namespace-filter">
<h3>Scenario: Apply namespace filter<a class="headerlink" href="#scenario-apply-namespace-filter" title="Link to this heading"></a></h3>
<ul class="simple">
<li><p><strong>GIVEN</strong> indexed chunks across two namespaces</p></li>
<li><p><strong>WHEN</strong> a query specifies <code class="docutils literal notranslate"><span class="pre">namespace</span> <span class="pre">=</span> <span class="pre">e2e_test_a</span></code></p></li>
<li><p><strong>THEN</strong> the final result set only includes chunks from that namespace, regardless of whether FAISS is shared or per-namespace</p></li>
</ul>
</section>
</section>
<section id="requirement-operations-stats-and-persistence">
<h2>Requirement: Operations, Stats, and Persistence<a class="headerlink" href="#requirement-operations-stats-and-persistence" title="Link to this heading"></a></h2>
<p>The system SHALL expose stats for FAISS (<code class="docutils literal notranslate"><span class="pre">ntotal</span></code>, training state, throughput) and OpenSearch (<code class="docutils literal notranslate"><span class="pre">_stats</span></code>, ingest/search latency), support pagination cursors (PIT + search_after, fused slicing), and provide backup/restore flows (OpenSearch snapshots, FAISS GPU→CPU serialization). Delete churn SHALL trigger guidance for periodic FAISS rebuilds.</p>
<section id="scenario-snapshot-and-restore-retrieval-state">
<h3>Scenario: Snapshot and restore retrieval state<a class="headerlink" href="#scenario-snapshot-and-restore-retrieval-state" title="Link to this heading"></a></h3>
<ul class="simple">
<li><p><strong>GIVEN</strong> a scheduled maintenance window</p></li>
<li><p><strong>WHEN</strong> the operator triggers OpenSearch snapshot and FAISS serialization</p></li>
<li><p><strong>THEN</strong> both stores are captured to durable storage</p></li>
<li><p><strong>AND</strong> restoration into a clean environment reproduces identical <code class="docutils literal notranslate"><span class="pre">vector_id</span></code> alignments and comparable scores within float tolerances</p></li>
<li><p><strong>AND</strong> operational dashboards display current FAISS ntotal, delete ratio, last training timestamp, OpenSearch ingestion/search latency percentiles, and alert when thresholds defined in configuration are exceeded</p></li>
</ul>
</section>
</section>
<section id="requirement-observability-and-logging">
<h2>Requirement: Observability and Logging<a class="headerlink" href="#requirement-observability-and-logging" title="Link to this heading"></a></h2>
<p>The ingestion and retrieval components SHALL emit structured logs with trace IDs, expose Prometheus-compatible metrics (ingest throughput, FAISS latency, OpenSearch latency, fusion timings, error counts), and provide per-request tracing that correlates sparse and dense sub-requests.</p>
<section id="scenario-trace-hybrid-search-latency-regression">
<h3>Scenario: Trace hybrid search latency regression<a class="headerlink" href="#scenario-trace-hybrid-search-latency-regression" title="Link to this heading"></a></h3>
<ul class="simple">
<li><p><strong>GIVEN</strong> observability tooling detects elevated latency</p></li>
<li><p><strong>WHEN</strong> an engineer inspects traces for <code class="docutils literal notranslate"><span class="pre">POST</span> <span class="pre">/v1/hybrid-search</span></code></p></li>
<li><p><strong>THEN</strong> they can see spans for BM25, SPLADE, FAISS, fusion, and result shaping with individual durations and error tags, enabling pinpointing of the degraded subsystem</p></li>
</ul>
</section>
</section>
<section id="requirement-validation-and-calibration-suite">
<h2>Requirement: Validation and Calibration Suite<a class="headerlink" href="#requirement-validation-and-calibration-suite" title="Link to this heading"></a></h2>
<p>An automated validation harness SHALL cover ingest integrity (field presence, dimension checks), dense self-hit accuracy (≥0.95 &#64;1 for IVF or 1.00 for Flat), sparse relevance sanity (≥90% self-match &#64;10), namespace filtering, pagination stability, fusion efficacy, highlight packaging, and calibration sweeps for <code class="docutils literal notranslate"><span class="pre">nprobe</span></code>/PQ parameters.</p>
<section id="scenario-run-end-to-end-validation-on-sample-corpus">
<h3>Scenario: Run end-to-end validation on sample corpus<a class="headerlink" href="#scenario-run-end-to-end-validation-on-sample-corpus" title="Link to this heading"></a></h3>
<ul class="simple">
<li><p><strong>GIVEN</strong> the provided JSONL dataset of sparse and dense features</p></li>
<li><p><strong>WHEN</strong> the validation command executes</p></li>
<li><p><strong>THEN</strong> all ingest, search, fusion, pagination, and backup checks pass with thresholds defined above, and calibration results are recorded for operational tuning</p></li>
<li><p><strong>AND</strong> the harness writes a human-readable report and machine JSON artifact indicating pass/fail per check, stored under <code class="docutils literal notranslate"><span class="pre">reports/validation/&lt;timestamp&gt;/</span></code></p></li>
</ul>
</section>
</section>
</section>


           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2025, DocsToKG Team.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>