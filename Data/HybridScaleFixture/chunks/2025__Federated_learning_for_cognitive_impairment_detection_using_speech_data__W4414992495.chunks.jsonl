{"doc_id": "2025__Federated_learning_for_cognitive_impairment_detection_using_speech_data__W4414992495", "source_path": "<redacted:source_path>", "chunk_id": 0, "source_chunk_idxs": [0], "num_tokens": 495, "text": "Frontiers | Federated learning for cognitive impairment detection using speech data\nFrontiers in Artificial Intelligence\nAbout us\nAbout us\n- Who we are\n- Mission and values\n- History\n- Leadership\n- Awards\n- Impact and progress\n- Frontiers' impact\n- Our annual reports\n- Publishing model\n- How we publish\n- Open access\n- Peer review\n- Research integrity\n- Research Topics\n- FAIR\u00b2 Data Management\n- Fee policy\n- Services\n- Societies\n- National consortia\n- Institutional partnerships\n- Collaborators\n- More from Frontiers\n- Frontiers Forum\n- Frontiers Planet Prize\n- Press office\n- Sustainability\n- Career opportunities\n- Contact us\nAll journals\nAll articles\nSubmit your research\nSearch\nFrontiers in Artificial Intelligence\nSections\nSections\n- AI for Human Learning and Behavior Change\n- AI in Business\n- AI in Finance\n- AI in Food, Agriculture and Water\n- Big Data and AI in High Energy Physics\n- Language and Computation\n- Logic and Reasoning in AI\n- Machine Learning and Artificial Intelligence\n- Medicine and Public Health\n- Natural Language Processing\n- Organoid Intelligence\n- Pattern Recognition\n- Technology and Law\nArticles\nResearch Topics\nEditorial board\nAbout journal\nAbout journal\n- Scope\n- Field chief editors\n- Mission &amp; scope\n- Facts\n- Journal sections\n- Open access statement\n- Copyright statement\n- Quality\n- For authors\n- Why submit?\n- Article types\n- Author guidelines\n- Editor guidelines\n- Publishing fees\n- Submission checklist\n- Contact editorial office\nAbout us\nAbout us\n- Who we are\n- Mission and values\n- History\n- Leadership\n- Awards\n- Impact and progress\n- Frontiers' impact\n- Our annual reports\n- Publishing model\n- How we publish\n- Open access\n- Peer review\n- Research integrity\n- Research Topics\n- FAIR\u00b2 Data Management\n- Fee policy\n- Services\n- Societies\n- National consortia\n- Institutional partnerships\n- Collaborators\n- More from Frontiers\n- Frontiers Forum\n- Frontiers Planet Prize\n- Press office\n- Sustainability\n- Career opportunities\n- Contact us\nAll journals\nAll articles\nSubmit your research\nFrontiers in Artificial Intelligence\nSections\nSections\n- AI for Human Learning and Behavior Change\n- AI in Business\n- AI in Finance\n- AI in Food, Agriculture and Water\n- Big Data and AI in High Energy Physics\n- Language and Computation\n- Logic and Reasoning in AI\n- Machine Learning and Artificial Intelligence\n- Medicine and Public Health\n- Natural Language Processing\n- Organoid Intelligence\n- Pattern Recognition\n- Technology and Law\nArticles\nResearch Topics\nEditorial board\nAbout journal\nAbout journal\n- Scope\n- Field chief editors\n- Mission &amp; scope\n- Facts\n- Journal sections\n- Open access statement\n- Copyright statement\n- Quality\n- For authors\n- Why submit?\n- Article types\n- Author guidelines\n- Editor guidelines\n- Publishing fees\n- Submission checklist\n- Contact editorial office\nFrontiers in Artificial Intelligence\nSections\nSections", "doc_items_refs": ["#/texts/1", "#/texts/2", "#/texts/3", "#/texts/4", "#/texts/5", "#/texts/6", "#/texts/7", "#/texts/8", "#/texts/9", "#/texts/10", "#/texts/11", "#/texts/12", "#/texts/13", "#/texts/14", "#/texts/15", "#/texts/16", "#/texts/17", "#/texts/18", "#/texts/19", "#/texts/20", "#/texts/21", "#/texts/22", "#/texts/23", "#/texts/24", "#/texts/25", "#/texts/26", "#/texts/27", "#/texts/28", "#/texts/29", "#/texts/30", "#/texts/31", "#/texts/32", "#/texts/33", "#/texts/34", "#/texts/35", "#/texts/36", "#/texts/37", "#/texts/38", "#/texts/39", "#/texts/40", "#/texts/41", "#/texts/42", "#/texts/43", "#/texts/44", "#/texts/45", "#/texts/46", "#/texts/47", "#/texts/48", "#/texts/49", "#/texts/50", "#/texts/51", "#/texts/52", "#/texts/53", "#/texts/54", "#/texts/55", "#/texts/56", "#/texts/57", "#/texts/58", "#/texts/59", "#/texts/60", "#/texts/61", "#/texts/62", "#/texts/63", "#/texts/64", "#/texts/65", "#/texts/66", "#/texts/67", "#/texts/68", "#/texts/69", "#/texts/70", "#/texts/71", "#/texts/72", "#/texts/73", "#/texts/74", "#/texts/75", "#/texts/76", "#/texts/77", "#/texts/78", "#/texts/79", "#/texts/80", "#/texts/81", "#/texts/82", "#/texts/83", "#/texts/84", "#/texts/85", "#/texts/86", "#/texts/87", "#/texts/88", "#/texts/89", "#/texts/90", "#/texts/91", "#/texts/92", "#/texts/93", "#/texts/94", "#/texts/95", "#/texts/96", "#/texts/97", "#/texts/98", "#/texts/99", "#/texts/100", "#/texts/101", "#/texts/102", "#/texts/103", "#/texts/104", "#/texts/105", "#/texts/106", "#/texts/107", "#/texts/108", "#/texts/109", "#/texts/110", "#/texts/111", "#/texts/112", "#/texts/113", "#/texts/114", "#/texts/115", "#/texts/116", "#/texts/117", "#/texts/118", "#/texts/119", "#/texts/120", "#/texts/121", "#/texts/122", "#/texts/123", "#/texts/124", "#/texts/125", "#/texts/126", "#/texts/127", "#/texts/128", "#/texts/129", "#/texts/130", "#/texts/131", "#/texts/132", "#/texts/133", "#/texts/134", "#/texts/135", "#/texts/136", "#/texts/137", "#/texts/138", "#/texts/139", "#/texts/140", "#/texts/141", "#/texts/142", "#/texts/143", "#/texts/144", "#/texts/145"], "page_nos": [], "uuid": "651a6128-f978-4a25-8e63-5e5a2edcf111"}
{"doc_id": "2025__Federated_learning_for_cognitive_impairment_detection_using_speech_data__W4414992495", "source_path": "<redacted:source_path>", "chunk_id": 1, "source_chunk_idxs": [1], "num_tokens": 220, "text": "Frontiers | Federated learning for cognitive impairment detection using speech data\n- AI for Human Learning and Behavior Change\n- AI in Business\n- AI in Finance\n- AI in Food, Agriculture and Water\n- Big Data and AI in High Energy Physics\n- Language and Computation\n- Logic and Reasoning in AI\n- Machine Learning and Artificial Intelligence\n- Medicine and Public Health\n- Natural Language Processing\n- Organoid Intelligence\n- Pattern Recognition\n- Technology and Law\nArticles\nResearch Topics\nEditorial board\nAbout journal\nAbout journal\n- Scope\n- Field chief editors\n- Mission &amp; scope\n- Facts\n- Journal sections\n- Open access statement\n- Copyright statement\n- Quality\n- For authors\n- Why submit?\n- Article types\n- Author guidelines\n- Editor guidelines\n- Publishing fees\n- Submission checklist\n- Contact editorial office\nSubmit your research\nSearch\nYour new experience awaits. Try the new design now and help us make it even better\nSwitch to the new experience\nORIGINAL RESEARCH article\nFront. Artif. Intell. , 09 October 2025\nSec. Medicine and Public Health\nVolume 8 - 2025 |\nhttps://doi.org/10.3389/frai.2025.1662859", "doc_items_refs": ["#/texts/146", "#/texts/147", "#/texts/148", "#/texts/149", "#/texts/150", "#/texts/151", "#/texts/152", "#/texts/153", "#/texts/154", "#/texts/155", "#/texts/156", "#/texts/157", "#/texts/158", "#/texts/159", "#/texts/160", "#/texts/161", "#/texts/162", "#/texts/163", "#/texts/164", "#/texts/165", "#/texts/166", "#/texts/167", "#/texts/168", "#/texts/169", "#/texts/170", "#/texts/171", "#/texts/172", "#/texts/173", "#/texts/174", "#/texts/175", "#/texts/176", "#/texts/177", "#/texts/178", "#/texts/179", "#/texts/180", "#/texts/181", "#/texts/182", "#/texts/183", "#/texts/184", "#/texts/185", "#/texts/186", "#/texts/187", "#/texts/188"], "page_nos": [], "uuid": "6ad775fa-c59a-4c58-b90a-ae95c9df11ee"}
{"doc_id": "2025__Federated_learning_for_cognitive_impairment_detection_using_speech_data__W4414992495", "source_path": "<redacted:source_path>", "chunk_id": 2, "source_chunk_idxs": [2], "num_tokens": 433, "text": "Federated learning for cognitive impairment detection using speech data\nJosep Blazquez-Folch\n1 \u2020\nMar\u00eda Limones Andrade\n2 \u2020\nBerta Calm\n1\nJuan Miguel Au\u00f1\u00f3n Garc\u00eda\n2\nMontserrat Alegret\n1,3\nNathalia Mu\u00f1oz\n1\nAmanda Cano\n1\nVictoria Fern\u00e1ndez\n1\nFernando Garc\u00eda-Guti\u00e9rrez\n1\nItziar De Rojas\n1,3\nPablo Garc\u00eda-Gonz\u00e1lez\n1\nCl\u00e0udia Oliv\u00e9\n1\nRaquel Puerta\n1\nMar\u00eda Capdevila-Bayo\n1\n\u00c1lvaro Mu\u00f1oz-Morales\n1\nPaula Bay\u00f3n-Buj\u00e1n\n1\nAndrea Miguel\n1\nLaura Montrreal\n1\nAna Espinosa\n1,3\nPilar Sanz-Cartagena\n1\nMaitee Rosende-Roca\n1\nCarla Zaldua\n4\nPeru Gabirondo\n4\nYahveth Cantero-Fortiz\n1,3\nMiren Jone Gurruchaga\n1\nLluis Tarraga\n1,3\nMerc\u00e8 Boada\n1,3\nAgust\u00edn Ruiz\n1,3,5,6\nMarta Marqui\u00e9\n1,3\nSergi Valero\n1,3 *\n- 1\nAce Alzheimer Center Barcelona - Universitat Internacional de Catalunya, Barcelona, Spain\n- 2\nDepartment of Artificial Intelligence and Big Data, GMV, Madrid, Spain\n- 3\nNetworking Research Center on Neurodegenerative Diseases (CIBERNED), Instituto de Salud Carlos III, Madrid, Spain\n- 4\nAccexible Impacto s.l., Urduliz, Bizkaia, Spain\n- 5\nGlenn Biggs Institute for Alzheimer's &amp; Neurodegenerative Diseases, University of Texas Health Science Center, San Antonio, TX, United States\n- 6\nDepartment of Microbiology, Immunology and Molecular Genetics, Long School of Medicine. University of Texas Health Science Center, San Antonio, TX, United States\nIntroduction:\nIn Alzheimer's disease (AD) research, clinical, neuroimaging, genetic, and biomarker data are vital for advancing its understanding and treatment. However, privacy concerns and limited datasets complicate data sharing. Federated learning (FL) offers a solution by enabling collaborative research while preserving data privacy.", "doc_items_refs": ["#/texts/190", "#/texts/191", "#/texts/192", "#/texts/193", "#/texts/194", "#/texts/195", "#/texts/196", "#/texts/197", "#/texts/198", "#/texts/199", "#/texts/200", "#/texts/201", "#/texts/202", "#/texts/203", "#/texts/204", "#/texts/205", "#/texts/206", "#/texts/207", "#/texts/208", "#/texts/209", "#/texts/210", "#/texts/211", "#/texts/212", "#/texts/213", "#/texts/214", "#/texts/215", "#/texts/216", "#/texts/217", "#/texts/218", "#/texts/219", "#/texts/220", "#/texts/221", "#/texts/222", "#/texts/223", "#/texts/224", "#/texts/225", "#/texts/226", "#/texts/227", "#/texts/228", "#/texts/229", "#/texts/230", "#/texts/231", "#/texts/232", "#/texts/233", "#/texts/234", "#/texts/235", "#/texts/236", "#/texts/237", "#/texts/238", "#/texts/239", "#/texts/240", "#/texts/241", "#/texts/242", "#/texts/243", "#/texts/244", "#/texts/245", "#/texts/246", "#/texts/247", "#/texts/248", "#/texts/249", "#/texts/250", "#/texts/251", "#/texts/252", "#/texts/253", "#/texts/254", "#/texts/255", "#/texts/256", "#/texts/257"], "page_nos": [], "uuid": "44cebcf5-4fdb-4b96-aa02-1991d6e71c48"}
{"doc_id": "2025__Federated_learning_for_cognitive_impairment_detection_using_speech_data__W4414992495", "source_path": "<redacted:source_path>", "chunk_id": 3, "source_chunk_idxs": [3], "num_tokens": 374, "text": "Federated learning for cognitive impairment detection using speech data\nMethods:\nThis study analyzed data from patients assessed at the Memory Unit of the Ace Alzheimer Center Barcelona who completed a standardized digital speech protocol. Acoustic features extracted from these recordings were used to distinguish between cognitively unimpaired (CU) and cognitively impaired (CI) individuals. The aim was to evaluate how data heterogeneity impacted the FL model performance across three scenarios: (1) equal contributions and class ratios, (2) unequal contributions, and (3) imbalanced class ratios. In each scenario, the performance of local models trained using an MLP feed-forward neural network on institutional data was analyzed and compared to a global model created by aggregating these local models using Federated Averaging (FedAvg) and Iterative Data Aggregation (IDA).\nResults:\nThe cohort included 2,239 participants: 221 CU individuals (mean age 66.8, 64.7% female) and 2,018 CI subjects, comprising 1,219 with mild cognitive impairment (mean age 74.3, 61.9% female) and 799 with mild AD dementia (mean age 80.8, 64.8% female). In scenarios 1 and 3, FL provided modest gains in accuracy and AUC. In scenario 2, FL markedly improved performance for the smaller dataset (balanced accuracy rising from 0.51 to 0.80) while preserving 0.86 accuracy in the larger dataset, highlighting scalability across heterogeneous conditions.\nConclusion:\nThese findings demonstrate the potential of FL to enable collaborative modeling of speech-based biomarkers for cognitive impairment detection, even under conditions of data imbalance and institutional disparity. This work highlights FL as a scalable and privacy-preserving approach for advancing digital health research in neurodegenerative diseases.", "doc_items_refs": ["#/texts/258", "#/texts/259", "#/texts/260", "#/texts/261", "#/texts/262", "#/texts/263"], "page_nos": [], "uuid": "b9744ede-7b97-4a26-97ad-2c45b0184694"}
{"doc_id": "2025__Federated_learning_for_cognitive_impairment_detection_using_speech_data__W4414992495", "source_path": "<redacted:source_path>", "chunk_id": 4, "source_chunk_idxs": [4], "num_tokens": 427, "text": "Federated learning for cognitive impairment detection using speech data\n1 Introduction\nDementia, particularly Alzheimer's disease (AD), poses a growing global health challenge among the aging population. In the United States alone, over 6.9 million individuals aged 65 and older are estimated to be living with AD, a number projected to nearly double to 13.8 million by 2060 (\nAlzheimer's Association, 2024\n). Notably, 10.9% of this demographic is affected by the disease (\nAlzheimer's Association, 2024\n), underscoring its increasing impact.\nAccurate diagnosis and effective treatment are complicated by the multifaceted nature of dementia, which is influenced by demographic, environmental, genetic, and biological factors. Artificial intelligence has emerged as a promising tool for cognitive-impairment screening, with machine learning (ML) and natural language processing applied to neuroimaging, electronic health records, speech, and other digital biomarkers. These methods show strong predictive performance and potential to improve diagnostic accuracy and efficiency, though concerns remain about misdiagnosis, confidentiality, and the psychological burden of screening (\nWurtz et al., 2025\n;\nArya et al., 2023\n). Among them, automated speech analysis has emerged as a non-invasive tool for detecting early cognitive decline (\nHajjar et al., 2023\n). Language impairments associated with dementia manifest as difficulties in both speech production and comprehension (\nBucks et al., 2000\n). However, large-scale studies leveraging speech data face significant obstacles, including concerns about patient privacy, speech de-identification, data sharing, and the need for collaboration across multiple research centers.\nFederated learning (FL) has emerged as a promising ML approach for addressing these challenges by enabling multi-institutional data analysis while preserving patient confidentiality. Unlike traditional centralized methods, FL allows decentralized model training, ensuring sensitive information remains local (\nKairouz et al., 2021\n;\nHardy et al., 2017\n). This framework is particularly well-suited for privacy-sensitive domains such as healthcare, facilitating collaborative research while mitigating data security risks.", "doc_items_refs": ["#/texts/265", "#/texts/266", "#/texts/267", "#/texts/268", "#/texts/269", "#/texts/270", "#/texts/271", "#/texts/272", "#/texts/273", "#/texts/274", "#/texts/275", "#/texts/276", "#/texts/277", "#/texts/278", "#/texts/279", "#/texts/280", "#/texts/281", "#/texts/282", "#/texts/283"], "page_nos": [], "uuid": "af7a57f7-5efc-4fb4-8bfd-3b6f3df4e4a0"}
{"doc_id": "2025__Federated_learning_for_cognitive_impairment_detection_using_speech_data__W4414992495", "source_path": "<redacted:source_path>", "chunk_id": 5, "source_chunk_idxs": [5], "num_tokens": 418, "text": "Federated learning for cognitive impairment detection using speech data\n1 Introduction\nAlthough FL has shown promise in various healthcare applications (\nTeo et al., 2024\n), its use for speech-based dementia detection remains scarce and underdeveloped. Traditional centralized approaches face limitations due to restricted data access, ethical concerns, and biased representation, while variability in language, demographics, and recording conditions undermines generalization (\nGarc\u00eda Guti\u00e9rrez et al., 2024\n;\nSharafeldeen et al., 2025\n). FL offers a potential solution to these challenges, yet it introduces its own complexities. A key issue is data heterogeneity, where variations in dataset size and class distribution across institutions can negatively impact model fairness and overall performance (\nHardy et al., 2017\n).\nTo our knowledge, until now there exists only a single prior work examining speech-based AD diagnosis within FL frameworks, which demonstrates its feasibility for AD detection from speech, with decentralized models achieving competitive performance while preserving privacy. However, these efforts rely on small, homogeneous datasets, and the impact of real-world heterogeneity on accuracy and fairness remains largely unexamined (\nMeerza et al., 2022\n).\nTo address this limitation, our study builds upon and significantly extends previous research by conducting a comprehensive evaluation of FL for dementia detection. Leveraging a substantially larger and more diverse dataset, we systematically evaluate model performance under various realistic scenarios, particularly emphasizing the challenges posed by data heterogeneity. Specifically, we investigate how data heterogeneity influences predictive accuracy and robustness. Our approach employs acoustic speech features within a multi-layer perceptron (MLP) neural network framework to distinguish between cognitively unimpaired (CU) and cognitively impaired (CI) individuals.\nBy examining the interplay between data variability and FL efficacy on a broader scale, this research provides deeper insights into optimizing FL models for real-world applications, ensuring both robust performance and equitable outcomes across diverse datasets.", "doc_items_refs": ["#/texts/284", "#/texts/285", "#/texts/286", "#/texts/287", "#/texts/288", "#/texts/289", "#/texts/290", "#/texts/291", "#/texts/292", "#/texts/293", "#/texts/294", "#/texts/295", "#/texts/296", "#/texts/297"], "page_nos": [], "uuid": "f75bfe2e-a03e-45f9-a766-a56adcdc255c"}
{"doc_id": "2025__Federated_learning_for_cognitive_impairment_detection_using_speech_data__W4414992495", "source_path": "<redacted:source_path>", "chunk_id": 6, "source_chunk_idxs": [6], "num_tokens": 151, "text": "Federated learning for cognitive impairment detection using speech data\n2 Methods\n2.1 Study participants\nThis study included data from individuals evaluated at the Memory Clinic from Ace Alzheimer Center Barcelona (Ace) between March 2022 and April 2023 (\nTable 1\n). All participants were diagnosed by a multidisciplinary team comprising neurologists, neuropsychologists, and social workers after completing a series of neurological, neuropsychological, and social assessments. Further details of the evaluation protocols are available elsewhere (\nGarc\u00eda Guti\u00e9rrez et al., 2024\n;\nAlegret et al., 2011\n;\nBoada et al., 2014\n).\nTable 1\nTable 1\n. Clinical and sociodemographic characteristics of the sample stratified by clinical condition.", "doc_items_refs": ["#/texts/300", "#/texts/301", "#/texts/302", "#/texts/303", "#/texts/304", "#/texts/305", "#/texts/306", "#/texts/307", "#/texts/308", "#/texts/309", "#/texts/310", "#/texts/311"], "page_nos": [], "uuid": "d8a06e20-d806-4c7a-ad49-9a44e9350e76"}
{"doc_id": "2025__Federated_learning_for_cognitive_impairment_detection_using_speech_data__W4414992495", "source_path": "<redacted:source_path>", "chunk_id": 7, "source_chunk_idxs": [7], "num_tokens": 433, "text": "Federated learning for cognitive impairment detection using speech data\n2 Methods\n2.2 Speech protocol and automated speech analysis\nAll participants completed a brief speech protocol using the acceXible app platform on a tablet in a quiet and controlled environment under the supervision of a neuropsychologist. The protocol comprised two tasks: first, the description of The Cookie Theft Picture in approximately 1 min, a common language assessment test (\nCummings, 2019\n); and second, a semantic verbal fluency test where participants listed as many animals as possible within 1 min.\nSpeech recordings were standardized to 16 kHz, with silence segments removed and noise reduction applied using the model in (\nDefossez et al., 2020\n). From the processed audio, in image description and verbal fluency tasks independently, various physical acoustic features were extracted, covering parameters related to frequency (pitch, jitter, formant 1,2, and 3 frequency and formant 1 bandwidth), signal energy/amplitude (shimmer, loudness and harmonics-to-noise ratio), and spectral parameters (alpha ratio, hammarberg index, spectral slope 0-500 Hz and 500-1500 Hz, formant 1,2, and 3 relative energy and harmonic difference H1-H2 and H1-A3). The extracted variables corresponded to those described in the extended Geneva Minimalistic Acoustic Parameter Set (eGeMAPS) (\nEyben et al., 2015\n), a standardized set of acoustic parameters linked to physiological voice changes, often used in neurological disease contexts (\nGarc\u00eda Guti\u00e9rrez et al., 2024\n;\nGarc\u00eda Guti\u00e9rrez et al., 2023\n). Feature extraction was performed using the OpenSmile (v2.5.0) (\nEyben et al., 2010\n) library, with a three-frame symmetric moving average across eighteen low-level descriptors, resulting in a total of 176 variables per participant. The full set of extracted features was carried forward to the analyses, with no dimensionality reduction or cross-site adjustments applied at the extraction stage. Further details on feature calculation are available in (\nAbyane et al., 2022\n).", "doc_items_refs": ["#/texts/313", "#/texts/314", "#/texts/315", "#/texts/316", "#/texts/317", "#/texts/318", "#/texts/319", "#/texts/320", "#/texts/321", "#/texts/322", "#/texts/323", "#/texts/324", "#/texts/325", "#/texts/326", "#/texts/327", "#/texts/328"], "page_nos": [], "uuid": "86a524ce-dadc-45f7-bc2e-8549faf49c8f"}
{"doc_id": "2025__Federated_learning_for_cognitive_impairment_detection_using_speech_data__W4414992495", "source_path": "<redacted:source_path>", "chunk_id": 8, "source_chunk_idxs": [8], "num_tokens": 331, "text": "Federated learning for cognitive impairment detection using speech data\n2 Methods\n2.3 Virtual scenarios\nUsing the initial data specified in Sections 2.1 and 2.2 from the Ace Alzheimer Center Barcelona, we simulated a FL environment involving two virtual independent institutions (Institution 1 and Institution 2). The institutions provided speech acoustic features, along with CU and CI labels, for their respective patients. Each institution uploaded its data to its computing node, and three scenarios were designed to comprehensively analyze how dataset characteristics affect model performance. These scenarios, detailed in\nTable 2\n, varied by dataset size and class proportions at each institution, enabling an evaluation of their impact on FL model effectiveness.\nTable 2\nTable 2\n. Distribution of total, cognitive impaired (CI) and cognitive unimpaired (CU) cases per institution across different scenarios.\nTwo different conditions were examined for each scenario: (1) individual training, where each institution trained its model using only local data, and (2) federated training, where both institutions collaborated to train a global model using FL.\nIn the individual training condition, each institution trained a model exclusively on its local data and evaluated on both its own and the other institution's data. This setup, yielding two distinct models trained on separate datasets, allowed for the assessment of how data volume and quality variations at each institution influenced model performance, particularly in scenarios of limited data availability. Conversely, in the federated training condition, a collaborative model was trained on data from both institutions, leveraging data diversity to enhance model robustness and generalizability. This approach capitalized on the combined dataset, improving the model's overall performance.", "doc_items_refs": ["#/texts/330", "#/texts/331", "#/texts/332", "#/texts/333", "#/texts/334", "#/texts/335", "#/texts/336", "#/texts/337"], "page_nos": [], "uuid": "11a5bead-9a5f-4e80-85ba-a5e6d1cab234"}
{"doc_id": "2025__Federated_learning_for_cognitive_impairment_detection_using_speech_data__W4414992495", "source_path": "<redacted:source_path>", "chunk_id": 9, "source_chunk_idxs": [9, 10, 11], "num_tokens": 249, "text": "Federated learning for cognitive impairment detection using speech data\n2 Methods\n2.3 Virtual scenarios\n2.3.1 Scenario 1: uniform sample size\nIn scenario 1, each institution contributes an equal amount of data with a uniform ratio of CI to CU cases. This setup ensures consistency in sample size and class distribution across institutions, allowing for an evaluation of the FL model's performance under balanced and evenly distributed data conditions.\n\nFederated learning for cognitive impairment detection using speech data\n2 Methods\n2.3 Virtual scenarios\n2.3.2 Scenario 2: varying sample size\nIn scenario 2, institutions have varying data sizes, but the ratio of CI to CU cases remains consistent. This setup evaluates the FL model's performance under imbalanced data distribution, focusing on its robustness and generalizability across institutions with unequal dataset sizes.\n\nFederated learning for cognitive impairment detection using speech data\n2 Methods\n2.3 Virtual scenarios\n2.3.3 Scenario 3: imbalanced class ratio\nIn scenario 3, institutions differ in their class distributions, with one having more CI cases and another more CU cases. This setup examines the FL model's ability to handle class distribution imbalances, reflecting real-world challenges where institutional data often lacks uniformity.", "doc_items_refs": ["#/texts/339", "#/texts/341", "#/texts/343"], "page_nos": [], "uuid": "42137c63-9232-48c9-b6c9-788e44a15344"}
{"doc_id": "2025__Federated_learning_for_cognitive_impairment_detection_using_speech_data__W4414992495", "source_path": "<redacted:source_path>", "chunk_id": 10, "source_chunk_idxs": [12], "num_tokens": 411, "text": "Federated learning for cognitive impairment detection using speech data\n2 Methods\n2.4 Neural network architecture and federated learning setup\nIn FL, designing an effective network requires balancing local device limitations, like computational capacity and data availability, with the need for coordinated global model updates to ensure convergence (\nAbyane et al., 2022\n). The goal is not necessarily the highest model accuracy, but overcoming challenges of cross-institution collaboration while maintaining data privacy. This highlights the advantages and challenges of secure, collaborative data sharing in heterogeneous environments, along with issues of privacy and model convergence.\nTo address these challenges, we employed a feed-forward MLP as the local model architecture. The MLP consisted of an input layer with 176 neurons, each corresponding to an input acoustic feature, followed by two hidden layers with 20 neurons each, utilizing ReLU activation functions. The output layer comprised a single neuron with a sigmoid activation function for binary classification. The network architecture is illustrated in\nFigure 1\nin the local model framework.\nFigure 1\nFigure 1\n. Federated learning architecture using Federated Averaging (FedAvg) and Iterative Data Aggregation (IDA) across two institutions for decentralized multi-layer perceptron-based classification of cognitive impairment from speech-derived acoustic features.\nLocal models were trained using stochastic gradient descent (\nWojtowytsch, 2021\n) with an initial learning rate of 0.01. To enhance convergence stability, an exponential learning rate scheduler with a decay factor of 0.95 per step was applied. Training was conducted with a batch size of 32 over 150 epochs. Hyperparameters were not systematically tuned but chosen based on initial configurations with manual adjustments. The binary cross-entropy loss function was employed, appropriate for binary classification tasks. The dataset was split into training (70%) and test (30%) sets with no overlap (training \u2229 test = \u2205). Performance was evaluated using standard classification metrics, including the Area Under the ROC Curve (AUC-ROC).", "doc_items_refs": ["#/texts/345", "#/texts/346", "#/texts/347", "#/texts/348", "#/texts/349", "#/texts/350", "#/texts/351", "#/texts/352", "#/texts/353", "#/texts/354", "#/texts/355", "#/texts/356"], "page_nos": [], "uuid": "0c5d5ecc-f509-4f54-bc4d-107407e2d868"}
{"doc_id": "2025__Federated_learning_for_cognitive_impairment_detection_using_speech_data__W4414992495", "source_path": "<redacted:source_path>", "chunk_id": 11, "source_chunk_idxs": [13], "num_tokens": 512, "text": "Federated learning for cognitive impairment detection using speech data\n2 Methods\n2.4 Neural network architecture and federated learning setup\nRather than employing explicit regularization techniques such as Dropout, Batch Normalization, or weight decay, overfitting control was achieved through the compact architecture of the network, monitoring of validation performance, and the use of class-balancing weights in the loss function. To account for class imbalance, weights were initialized inversely proportional to class frequency, normalized by a factor of 2, thereby assigning greater importance to the minority class. These weights were dynamically applied at each batch to maintain balanced contributions throughout training.\nTo aggregate locally trained models, we employed the Federated Averaging (FedAvg) algorithm (\nMcMahan et al., 2017\n), which computes a weighted average of local model parameters, assigning weights proportional to the number of training samples per client. Mathematically, this aggregation is defined as:\nw\nt\n+\n1\n=\n\u2211\nk\n=\n1\nK\nn\nk\nn\nw\nk\nt\n+\n1\nwhere w t + 1 denotes the updated global model parameters, w k t + 1 represents the parameters obtained from client k after local training, nk is the number of training samples held by client k , n = \u2211 k = 1 K n k is the total number of training samples, and K is the number of participating clients (with K = 2 in our study). This approach assumes that clients with larger datasets generate more reliable model updates, and thus should exert greater influence on the aggregated global model.\nHowever, FedAvg is known to be vulnerable in federated settings characterized by non-independent and identically distributed (non-IID) data or unbalanced sample sizes, where local models can diverge significantly due to class imbalances or other localized biases. As a result, weighting updates solely based on data volume can inadvertently amplify the influence of low-quality or even adversarial model updates, ultimately degrading the robustness and generalization ability of the global model.\nTo mitigate this issue, we incorporated the Iterative Data Aggregation (IDA) algorithm (\nYeganeh et al., 2020\n), a robust aggregation strategy that assigns weights based on the similarity of local models to the average model. Specifically, IDA downweights local models that deviate significantly from the average by computing weights inversely proportional to their \u21131-distance from the average model. The weighting coefficient for each local model k is given by:\n\u03b1\nk\n=\n1", "doc_items_refs": ["#/texts/357", "#/texts/358", "#/texts/359", "#/texts/360", "#/texts/361", "#/texts/362", "#/texts/363", "#/texts/364", "#/texts/365", "#/texts/366", "#/texts/367", "#/texts/368", "#/texts/369", "#/texts/370", "#/texts/371", "#/texts/372", "#/texts/373", "#/texts/374", "#/texts/375", "#/texts/376", "#/texts/377", "#/texts/378", "#/texts/379", "#/texts/380", "#/texts/381", "#/texts/382", "#/texts/383", "#/texts/384", "#/texts/385", "#/texts/386", "#/texts/387"], "page_nos": [], "uuid": "1c2e768a-16fb-47f6-8832-7fc4b54eb782"}
{"doc_id": "2025__Federated_learning_for_cognitive_impairment_detection_using_speech_data__W4414992495", "source_path": "<redacted:source_path>", "chunk_id": 12, "source_chunk_idxs": [14, 15], "num_tokens": 314, "text": "Federated learning for cognitive impairment detection using speech data\n2 Methods\n2.4 Neural network architecture and federated learning setup\nZ\n(\nw\nAvg\nt\n\u2212\nw\nk\nt\n1\n+\n\u03b5\n)\n\u2212\n1\nwhere w Avg t = 1 K \u2211 k = 1 K w k t is the average of the local models at round t , Z is a normalization factor to ensure \u03b1 k all sum 1 and \u03b5 is a small constant to prevent division by zero. The aggregation process is then defined as:\nw\nt\n+\n1\n=\n\u2211\nk\n=\n1\nK\n\u03b1\nk\nw\nk\nt\n+\n1\nBy relying on model similarity rather than sample count, IDA enhances robustness to statistical heterogeneity, noisy updates, and outlier models, which are common in real-world federated scenarios. The entire aggregation process is illustrated in\nFigure 1\n.\n\nFederated learning for cognitive impairment detection using speech data\n2 Methods\n2.4 Neural network architecture and federated learning setup\n2.4.1 Development\nThe FL system was implemented using Python 3.11.9 with uTile (\nGMV, 2024\n), which internally leverages PyTorch 2.0.0 for deep learning model development. In this setup, uTile coordinates training across multiple decentralized nodes, allowing each to train locally on its data while sharing model updates to a central aggregator. This approach enhances data privacy by avoiding the transfer of raw data between nodes and the central server. Instead of transmitting raw data, only model weights or gradients are communicated, preserving data privacy while enabling collaborative learning.", "doc_items_refs": ["#/texts/388", "#/texts/389", "#/texts/390", "#/texts/391", "#/texts/392", "#/texts/393", "#/texts/394", "#/texts/395", "#/texts/396", "#/texts/397", "#/texts/398", "#/texts/399", "#/texts/400", "#/texts/401", "#/texts/402", "#/texts/403", "#/texts/404", "#/texts/405", "#/texts/406", "#/texts/407", "#/texts/408", "#/texts/409", "#/texts/410", "#/texts/411", "#/texts/412", "#/texts/413", "#/texts/414", "#/texts/415", "#/texts/416", "#/texts/417", "#/texts/418", "#/texts/419", "#/texts/420", "#/texts/421", "#/texts/422", "#/texts/423", "#/texts/425", "#/texts/426", "#/texts/427"], "page_nos": [], "uuid": "b20d0850-12bf-4daa-b1da-b0f4eac1cc99"}
{"doc_id": "2025__Federated_learning_for_cognitive_impairment_detection_using_speech_data__W4414992495", "source_path": "<redacted:source_path>", "chunk_id": 13, "source_chunk_idxs": [16], "num_tokens": 402, "text": "Federated learning for cognitive impairment detection using speech data\n3 Results\nData from 2,239 participants were analyzed: 221 individuals who were CU, showing no objective cognitive or functional impairment (CDR = 0) (\nJessen et al., 2014\n) and 2,018 participants who exhibited CI, including patients with mild cognitive impairment (MCI) (\nn\n= 1,219, CDR = 0.5) (\nPetersen, 2004\n) and dementia due to AD (\nn\n= 799, CDR &gt; 0.5) (\nMcKhann et al., 2011\n).\nTable 1\nshows the clinical and sociodemographic characteristics of the sample used for this study.\nModel performance was evaluated across three simulated FL scenarios designed to assess the effects of data imbalance and heterogeneity (\nTable 3\n). In scenario 1, where institutions contributed equally and class distributions were identical, local models achieved comparable balanced accuracies (0.71 and 0.73). Under FL, performance improved modestly: balanced accuracy increased to 0.73 and 0.79, and sensitivity rose from 0.69 to 0.82 at Node 1 and from 0.71 to 0.83 at Node 2, reflecting better detection of CI cases. Precision remained consistently high (&gt;0.95) across all models. Specificity was stable at Node 2 but declined slightly at Node 1 (0.73 to 0.64). Importantly, FL enhanced overall discriminative ability, with AUC rising from 0.76 to 0.81 at Node 1 and from 0.82 to 0.87 at Node 2, and F1-score increasing from 0.80 to 0.88 at Node 1 and from 0.82 to 0.90 at Node 2 (\nTable 4\n).\nTable 3\nTable 3\n. Sample sizes and corresponding train-test splits for each node across three scenarios.\nTable 4\nTable 4\n. Classification performance metrics for cognitive impairment prediction across three scenarios settings.", "doc_items_refs": ["#/texts/429", "#/texts/430", "#/texts/431", "#/texts/432", "#/texts/433", "#/texts/434", "#/texts/435", "#/texts/436", "#/texts/437", "#/texts/438", "#/texts/439", "#/texts/440", "#/texts/441", "#/texts/442", "#/texts/443", "#/texts/444", "#/texts/445", "#/texts/446", "#/texts/447", "#/texts/448", "#/texts/449", "#/texts/450", "#/texts/451", "#/texts/452"], "page_nos": [], "uuid": "49f3ef85-cf12-4c79-8b71-22658cbfc451"}
{"doc_id": "2025__Federated_learning_for_cognitive_impairment_detection_using_speech_data__W4414992495", "source_path": "<redacted:source_path>", "chunk_id": 14, "source_chunk_idxs": [17], "num_tokens": 469, "text": "Federated learning for cognitive impairment detection using speech data\n3 Results\nIn scenario 2, with a strong imbalance in dataset size, with Node 1 contributing only 10% of the total data (\nTable 3\n), the local model at that node struggled to identify CI cases, with a sensitivity of just 0.02 and a balanced accuracy of 0.51. This reflects the model's inability to generalize with such limited training data. However, when applying FL, performance at Node 1 improved dramatically: balanced accuracy rose to 0.80 and sensitivity to 0.93, F1-score to 0.94, and AUC to 0.89, showing that FL training enabled robust CI detection. At Node 2, which had a much larger dataset, high performance was maintained under FL (balanced accuracy 0.70, F1-score 0.92, AUC 0.84), underscoring the scalability of the approach and its ability to distribute benefits fairly across nodes of unequal size. Notably, specificity decreased at both nodes (from 1.00 to 0.67 at Node 1 and from 0.77 to 0.51 at Node 2), reflecting a trade-off where improved CI detection came at the expense of more CU misclassifications.\nIn scenario 3, class distribution was imbalanced across institutions, with Node 1 having 97% CI cases and only 3% CU cases, while Node 2 had a more representative mix (\nTable 3\n). Local models performed similarly to scenario 1, with balanced accuracies of 0.70 (Node 1) and 0.74 (Node 2). Under FL, Node 1 maintained similar balanced accuracy (0.71) but with shifted trade-offs: sensitivity decreased from 0.71 to 0.57 and F1-score from 0.82 to 0.73, while specificity improved from 0.69 to 0.85, suggesting that FL training allowed the model to better identify CU cases despite their scarcity. Node 2 showed stable balanced accuracy (0.72) and slightly higher AUC (0.84), indicating that federated training conferred benefits, particularly in recognizing minority-class CU samples without loss of overall classification power.\nThe complete confusion matrices for each scenario, including local and FL models, are provided in the\nSupplementary Table S1\n.", "doc_items_refs": ["#/texts/453", "#/texts/454", "#/texts/455", "#/texts/456", "#/texts/457", "#/texts/458", "#/texts/459", "#/texts/460", "#/texts/461"], "page_nos": [], "uuid": "25c59a15-11bb-46ce-b762-dd4cb1a0ad94"}
{"doc_id": "2025__Federated_learning_for_cognitive_impairment_detection_using_speech_data__W4414992495", "source_path": "<redacted:source_path>", "chunk_id": 15, "source_chunk_idxs": [18], "num_tokens": 281, "text": "Federated learning for cognitive impairment detection using speech data\n4 Discussions and conclusions\nIn this study, an MLP model was trained using speech data and developed using a federated network to predict CI, specifically distinguishing between cognitively healthy individuals, and patients with MCI and dementia. FL was tested to confirm its ability to enable collaboration among multiple institutions while safeguarding patient privacy. This decentralized approach is particularly advantageous in healthcare, where privacy is a significant concern, as it facilitates multi-site model training without requiring the exchange of raw data (\nZhang et al., 2024\n).\nThe choice of MLP reflects the trade-offs inherent in FL. While more complex architectures (e.g., CNNs, RNNs, Transformers) may achieve higher performance in centralized settings, they are computationally demanding and more prone to divergence under heterogeneous data. MLPs, in contrast, are lightweight, stable, and communication-efficient, aligning well with structured acoustic features such as the 176 descriptors used here. Empirically, this balance proved effective: the MLP achieved strong AUC and F1-scores across scenarios, while FL improved sensitivity in low-data nodes and enhanced generalization under class imbalance. Thus, the MLP offered the most pragmatic compromise between expressive power, robustness, and scalability (\nZhang et al., 2024\n).", "doc_items_refs": ["#/texts/463", "#/texts/464", "#/texts/465", "#/texts/466", "#/texts/467", "#/texts/468"], "page_nos": [], "uuid": "c0180f55-6d49-4a0a-8c9c-348e10c16e81"}
{"doc_id": "2025__Federated_learning_for_cognitive_impairment_detection_using_speech_data__W4414992495", "source_path": "<redacted:source_path>", "chunk_id": 16, "source_chunk_idxs": [19], "num_tokens": 459, "text": "Federated learning for cognitive impairment detection using speech data\n4 Discussions and conclusions\nEqually important was the choice of aggregation strategy. The combination of FedAvg and IDA proved particularly suitable, as it consistently improved performance under challenging conditions. In Scenario 2, where the smaller institution held only 10% of the data, local training nearly failed (sensitivity = 0.02), yet the federated model raised sensitivity to 0.93 and AUC to 0.89, showing clear benefits for underrepresented nodes. In Scenario 3 with severe class imbalance, this combination also improved specificity (0.69 to 0.85) and AUC (0.79 to 0.81), enhancing recognition of CU cases. FedAvg offered scalability and efficiency, while IDA mitigated heterogeneity, together providing a balanced and pragmatic solution (\nMeerza et al., 2022\n). Other strategies, such as FedProx or Scaffold, address non-IID conditions by adding proximal terms or variance-reducing corrections, but they require additional hyperparameter tuning and may increase communication or computation costs, making them less practical for early-stage clinical deployment. Similarly, clustered FL can personalize models for subgroups, but at the expense of interpretability and cross-site comparability, which are essential in healthcare. Against this backdrop, FedAvg combined with IDA offered the best balance between simplicity, robustness, and feasibility (\nQi et al., 2023\n).\nOverall, the federated MLP consistently achieved AUC values above 80%, demonstrating reliable discrimination between CU and CI. Its greatest impact emerged under scarcity and imbalance: in Scenario 2, balanced accuracy rose from 0.51 to 0.80 and sensitivity from 0.02 to 0.93, while in Scenario 3, FL improved specificity and AUC, aiding recognition of minority CU cases. By contrast, gains in balanced settings (Scenario 1) were modest, indicating that FL's strength lies less in boosting absolute accuracy than in ensuring fair and robust performance across heterogeneous institutions. These results highlight FL as a privacy-preserving framework that promotes equity, allowing smaller or skewed sites to contribute meaningfully without being disadvantaged.", "doc_items_refs": ["#/texts/469", "#/texts/470", "#/texts/471", "#/texts/472", "#/texts/473", "#/texts/474"], "page_nos": [], "uuid": "386a68b3-0d1d-438b-b0c2-d2e82e93c4e2"}
{"doc_id": "2025__Federated_learning_for_cognitive_impairment_detection_using_speech_data__W4414992495", "source_path": "<redacted:source_path>", "chunk_id": 17, "source_chunk_idxs": [20], "num_tokens": 360, "text": "Federated learning for cognitive impairment detection using speech data\n4 Discussions and conclusions\nTaken together, the findings confirm that the decentralized nature of FL provides a scalable and privacy-preserving solution for CI detection, enabling robust model development without direct data sharing (\nMeerza et al., 2022\n). By addressing dataset size inequality and class imbalance, FL supports fairer predictions across diverse populations and is particularly valuable for detecting subtle cognitive changes in early disease stages (\nMateus et al., 2023\n). Beyond modest performance improvements, its benefits extend to equity across institutions, compliance with privacy regulations, enhanced security through decentralization, and scalability across heterogeneous clinical environments.\nHowever, several limitations should be acknowledged. First, although the cohort included 2,239 participants, all data came from a single institution. The simulated disparities between two virtual sites with harmonized preprocessing cannot replicate true cross-site heterogeneity, where differences in devices, demographics, diagnostic protocols, and annotation quality are more pronounced. Real-world clinical settings also introduce variability in speech tasks, legal constraints, and annotation standards, which may affect both convergence and fairness. These factors highlight the need for validation beyond controlled simulations.\nSecond, while FL demonstrates strong potential for collaborative and privacy-preserving modeling, it is not immune to security vulnerabilities. Risks such as model inversion attacks, membership inference, and data leakage could compromise patient confidentiality or model integrity. Mitigating these risks will require safeguards including differential privacy, secure aggregation, and adversarial robustness strategies, alongside standardized monitoring and quality control, to ensure that FL systems remain safe and trustworthy in clinical deployment (\nVasa et al., 2024\n).", "doc_items_refs": ["#/texts/475", "#/texts/476", "#/texts/477", "#/texts/478", "#/texts/479", "#/texts/480", "#/texts/481", "#/texts/482", "#/texts/483"], "page_nos": [], "uuid": "df4565ee-1c90-42d5-838b-92bbc052d6a5"}
{"doc_id": "2025__Federated_learning_for_cognitive_impairment_detection_using_speech_data__W4414992495", "source_path": "<redacted:source_path>", "chunk_id": 18, "source_chunk_idxs": [21], "num_tokens": 353, "text": "Federated learning for cognitive impairment detection using speech data\n4 Discussions and conclusions\nFuture work should prioritize multi-institutional pilots to evaluate scalability across larger networks (e.g., 5-10 sites) using diverse devices, protocols, and languages, thereby testing cross-linguistic generalizability. These studies should compare aggregation strategies (e.g., FedAvg vs. adaptive methods) and investigate personalization, domain adaptation, and harmonization frameworks to balance local adaptation with global performance. Evaluation must extend beyond AUC and F1-scores to include fairness, calibration, and node-specific robustness, ensuring that benefits are not driven solely by data-rich sites. Expanding FL to geographically distributed cohorts and incorporating multimodal data sources, such as cognitive assessments, neuroimaging, and electronic health records, will further enhance diagnostic accuracy and clinical applicability. To achieve this, key steps include: (1) establishing multi-institutional pilots under real-world conditions, (2) developing standardized protocols for data harmonization and evaluation across sites, (3) creating interoperable, privacy-compliant FL infrastructure aligned with regulations, and (4) building decision-support tools to integrate FL outputs into clinical workflows. Establishing harmonized speech protocols and secure, standardized infrastructure will be essential to move beyond experimental validation and enable safe deployment in healthcare systems (\nDhade and Shirke, 2024\n).\nOverall, this study highlights the promise of FL as a scalable, secure, and effective approach for early detection of cognitive impairment. By enabling privacy-preserving collaboration across institutions, FL addresses key challenges in digital health research and opens new avenues for developing accessible and equitable diagnostic tools for neurodegenerative diseases.", "doc_items_refs": ["#/texts/484", "#/texts/485", "#/texts/486", "#/texts/487"], "page_nos": [], "uuid": "9a90fce1-74ef-4a98-95fe-bc69e412ec01"}
{"doc_id": "2025__Federated_learning_for_cognitive_impairment_detection_using_speech_data__W4414992495", "source_path": "<redacted:source_path>", "chunk_id": 19, "source_chunk_idxs": [22, 23], "num_tokens": 210, "text": "Federated learning for cognitive impairment detection using speech data\nData availability statement\nThe datasets presented in this article are not readily available because the datasets generated and/or analyzed contain human privacy-sensitive data but are available from the corresponding author on reasonable request. Requests to access the datasets should be directed to Sergi Valero, c3ZhbGVyb0BmdW5kYWNpb2FjZS5vcmc= .\n\nFederated learning for cognitive impairment detection using speech data\nEthics statement\nThe studies involving humans were approved by Hospital Universitari de Bellvitge (Barcelona) (ref. PR007/22) in compliance with Spanish biomedical laws (Law 14/2007, July 3, regarding biomedical research; Royal Decree 1716/2011, November 18) and adhered to the principles of the Declaration of Helsinki. The studies were conducted in accordance with the local legislation and institutional requirements. Written informed consent for participation in this study was provided by the participants' legal guardians/next of kin.", "doc_items_refs": ["#/texts/489", "#/texts/491"], "page_nos": [], "uuid": "46044c52-352b-4dc7-a01a-af24d32ef98e"}
{"doc_id": "2025__Federated_learning_for_cognitive_impairment_detection_using_speech_data__W4414992495", "source_path": "<redacted:source_path>", "chunk_id": 20, "source_chunk_idxs": [24], "num_tokens": 469, "text": "Federated learning for cognitive impairment detection using speech data\nAuthor contributions\nJB-F: Formal analysis, Writing - original draft, Writing - review &amp; editing, Visualization, Methodology, Software. ML: Methodology, Writing - review &amp; editing, Formal analysis, Visualization, Software, Writing - original draft. BC: Formal analysis, Visualization, Writing - original draft, Methodology, Writing - review &amp; editing. JA: Writing - review &amp; editing, Writing - original draft, Methodology, Software, Conceptualization. MA: Investigation, Writing - review &amp; editing. NM: Writing - review &amp; editing, Investigation. AC: Funding acquisition, Writing - review &amp; editing. VF: Writing - review &amp; editing. FG-G: Software, Formal analysis, Writing - review &amp; editing, Writing - original draft, Data curation, Methodology. ID: Writing - review &amp; editing, Funding acquisition. PG-G: Writing - review &amp; editing. CO: Writing - review &amp; editing. RP: Writing - review &amp; editing. MC-B: Writing - review &amp; editing. \u00c1M-M: Writing - review &amp; editing. PB-B: Writing - review &amp; editing. AM: Writing - review &amp; editing. LM: Writing - review &amp; editing. AE: Writing - review &amp; editing, Investigation. PS-C: Investigation, Writing - review &amp; editing. M-RR: Writing - review &amp; editing, Investigation. CZ: Writing - review &amp; editing, Software. PG: Software, Writing - review &amp; editing. YC-F: Writing - review &amp; editing. MG: Conceptualization, Writing - review &amp; editing. LT: Writing - review &amp; editing. MB: Funding acquisition, Writing - review &amp; editing, Conceptualization. AR: Funding acquisition, Writing - review &amp; editing. MM: Investigation, Writing - original draft, Writing - review &amp; editing, Funding acquisition, Methodology. SV: Project administration, Writing - original draft, Methodology, Writing - review &amp; editing, Funding acquisition, Conceptualization.", "doc_items_refs": ["#/texts/493"], "page_nos": [], "uuid": "49ebb9eb-4e7f-4abe-b87f-5c39dc669bd8"}
{"doc_id": "2025__Federated_learning_for_cognitive_impairment_detection_using_speech_data__W4414992495", "source_path": "<redacted:source_path>", "chunk_id": 21, "source_chunk_idxs": [25], "num_tokens": 436, "text": "Federated learning for cognitive impairment detection using speech data\nFunding\nThe author(s) declare that financial support was received for the research and/or publication of this article. This project has received funding from R&amp;D Missions in the Artificial Intelligence program, which is part of the Spain Digital 2025 Agenda and the National Artificial Intelligence Strategy and financed by the European Union through Next Generation EU funds (project TARTAGLIA, exp.MIA.2021.M02.0005). This project has also received funding from the Instituto de Salud Carlos III (ISCIII) Acci\u00f3n Estrat\u00e9gica en Salud, integrated in the Spanish National RCDCI Plan and financed by ISCIII Subdirecci\u00f3n General de Evaluaci\u00f3n and the Fondo Europeo de Desarrollo Regional (FEDER-Una manera de hacer Europa) grant PI19/00335 awarded to MM, grant PI17/01474 awarded to MB, grants AC17/00100, PI19/01301 and PI22/01403 awarded to AR and by the European Union Joint Programme-Neurodegenerative Disease Research (JPND) Multinational research projects on Personalized Medicine for Neurodegenerative Diseases/Instituto de Salud Carlos III grant AC19/00097 awarded to AR and grant FI20/00215 from the Instituto de Salud Carlos III (ISCIII) awarded to ID. MM received funding support from the European Union's Horizon 2020 research and innovation programme under the Marie Sk\u0142odowska-Curie grant agreement N\u00b0 796706. AR and MB received support from the European Union/EFPIA Innovative Medicines Initiative Joint undertaking ADAPTED and MOPEAD projects (grant numbers 115975 and 115985, respectively). AC received support from the Instituto de Salud Carlos III (ISCIII) under the grant Sara Borrell (CD22/00125) and the Spanish Ministry of Science and Innovation, Proyectos de Generaci\u00f3n de Conocimiento grant PID2021-122473OA-I00.", "doc_items_refs": ["#/texts/495"], "page_nos": [], "uuid": "0c88d608-1428-4935-98ad-c494fd82409a"}
{"doc_id": "2025__Federated_learning_for_cognitive_impairment_detection_using_speech_data__W4414992495", "source_path": "<redacted:source_path>", "chunk_id": 22, "source_chunk_idxs": [26, 27], "num_tokens": 373, "text": "Federated learning for cognitive impairment detection using speech data\nAcknowledgments\nThe authors are grateful to all patients who consented to participate for their significant contribution to making this project possible.\n\nFederated learning for cognitive impairment detection using speech data\nConflict of interest\nCZ and ML were employed at GMV. PG-G was employed at Accexible Impacto s.l.. AR is member of the scientific advisory board of Landsteiner Genmed and Grifols SA. AR has stocks of Landsteiner Genmed. MB has consulted for Araclon, Avid, Grifols, Lilly, Nutricia, Roche, Eisai and Servier. She received fees from lectures and funds for research from Araclon, Biogen, Grifols, Nutricia, Roche and Servier. She reports grants/research funding from Abbvie, Araclon, Biogen Research Limited, Bioiberica, Grifols, Lilly, S.A, Merck Sharp &amp; Dohme, Kyowa Hakko Kirin, Laboratorios Servier, Nutricia SRL, Oryzon Genomics, Piramal Imaging Limited, Roche Pharma SA, and Schwabe Farma Iberica SLU, all outside the submitted work. She has not received personal compensations from these organizations. MM has consulted for F. Hoffmann-La Roche Ltd. and is a member of the Scientific Advisory Board of Biomarkers of Araclon.\nThe remaining authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.\nThe author(s) declared that they were an editorial board member of Frontiers, at the time of submission. This had no impact on the peer review process and the final decision.", "doc_items_refs": ["#/texts/497", "#/texts/499", "#/texts/500", "#/texts/501"], "page_nos": [], "uuid": "ee417410-41ef-4265-823e-f9c7048d3972"}
{"doc_id": "2025__Federated_learning_for_cognitive_impairment_detection_using_speech_data__W4414992495", "source_path": "<redacted:source_path>", "chunk_id": 23, "source_chunk_idxs": [28, 29, 30], "num_tokens": 217, "text": "Federated learning for cognitive impairment detection using speech data\nGenerative AI statement\nThe authors declare that no Gen AI was used in the creation of this manuscript.\nAny alternative text (alt text) provided alongside figures in this article has been generated by Frontiers with the support of artificial intelligence and reasonable efforts have been made to ensure accuracy, including review by the authors wherever possible. If you identify any issues, please contact us.\n\nFederated learning for cognitive impairment detection using speech data\nPublisher's note\nAll claims expressed in this article are solely those of the authors and do not necessarily represent those of their affiliated organizations, or those of the publisher, the editors and the reviewers. Any product that may be evaluated in this article, or claim that may be made by its manufacturer, is not guaranteed or endorsed by the publisher.\n\nFederated learning for cognitive impairment detection using speech data\nSupplementary material\nThe Supplementary material for this article can be found online at:\nhttps://www.frontiersin.org/articles/10.3389/frai.2025.1662859/full#supplementary-material", "doc_items_refs": ["#/texts/503", "#/texts/504", "#/texts/506", "#/texts/508", "#/texts/509"], "page_nos": [], "uuid": "7f1ff192-a0f2-4e40-b1a0-75bdf7753e4e"}
{"doc_id": "2025__Federated_learning_for_cognitive_impairment_detection_using_speech_data__W4414992495", "source_path": "<redacted:source_path>", "chunk_id": 24, "source_chunk_idxs": [31], "num_tokens": 489, "text": "Federated learning for cognitive impairment detection using speech data\nReferences\nAbyane, AE, Zhu, D, Souza, R, Ma, L, and Hemmati, H. (2022). Towards understanding quality challenges of the federated learning for neural networks: a first look from the lens of robustness.\nEmpirical Software Engineering\n. 28. doi: 10.1007/s10664-022-10262-y\nCrossref Full Text\n|\nGoogle Scholar\nAlegret, M., Espinosa, A., Vinyes-Junqu\u00e9, G., Valero, S., Hern\u00e1ndez, I., Tarraga Mestre, L., et al. (2011). Normative data of a brief neuropsychological battery for Spanish individuals older than 49.\nJ. Clin. Exp. Neuropsychol.\n34, 209-219. doi: 10.1080/13803395.2011.630652\nCrossref Full Text\n|\nGoogle Scholar\nAlzheimer's Association (2024). 2024 Alzheimer's disease facts and figures.\nAlzheimers Dement.\n20, 3708-3821. doi: 10.1002/alz.13809\nCrossref Full Text\n|\nGoogle Scholar\nArya, A. D., Verma, S. S., Chakarabarti, P., Chakrabarti, T., Elngar, A. A., Kamali, A. M., et al. (2023). A systematic review on machine learning and deep learning techniques in the effective diagnosis of Alzheimer's disease.\nBrain Informatics.\n10:17. doi: 10.1186/s40708-023-00195-7\nPubMed Abstract\n|\nCrossref Full Text\n|\nGoogle Scholar\nBoada, M., Tarraga, L., Hernandez, I., Valero, S., Alegret, M., Ruiz, A., et al. (2014). Design of a comprehensive Alzheimer's disease clinic and research center in Spain to meet critical patient and family needs.\nAlzheimers Dement.\n10, 409-415. doi: 10.1016/j.jalz.2013.03.006\nPubMed Abstract\n|\nCrossref Full Text\n|\nGoogle Scholar", "doc_items_refs": ["#/texts/511", "#/texts/512", "#/texts/513", "#/texts/514", "#/texts/515", "#/texts/516", "#/texts/517", "#/texts/518", "#/texts/519", "#/texts/520", "#/texts/521", "#/texts/522", "#/texts/523", "#/texts/524", "#/texts/525", "#/texts/526", "#/texts/527", "#/texts/528", "#/texts/529", "#/texts/530", "#/texts/531", "#/texts/532", "#/texts/533", "#/texts/534", "#/texts/535", "#/texts/536", "#/texts/537", "#/texts/538", "#/texts/539", "#/texts/540", "#/texts/541", "#/texts/542", "#/texts/543", "#/texts/544"], "page_nos": [], "uuid": "0bbc7ad7-df34-46a0-aa55-4efa65a40fb8"}
{"doc_id": "2025__Federated_learning_for_cognitive_impairment_detection_using_speech_data__W4414992495", "source_path": "<redacted:source_path>", "chunk_id": 25, "source_chunk_idxs": [32], "num_tokens": 436, "text": "Federated learning for cognitive impairment detection using speech data\nReferences\nBucks, R. S., Singh, S., Cuerden, J. M., and Wilcock, G. K. (2000). Analysis of spontaneous, conversational speech in dementia of Alzheimer type: evaluation of an objective technique for analysing lexical performance.\nAphasiology\n14, 71-91. doi: 10.1080/026870300401603\nCrossref Full Text\n|\nGoogle Scholar\nCummings, L. (2019). Describing the cookie theft picture: sources of breakdown in Alzheimer's dementia.\nPragmat. Soc.\n10, 153-176. doi: 10.1075/ps.17011.cum\nCrossref Full Text\n|\nGoogle Scholar\nDefossez, A, Synnaeve, G, and Adi, Y. (2020). Real time speech enhancement in the waveform domain. doi: 10.48550/arXiv.2006.12847\nCrossref Full Text\n|\nGoogle Scholar\nDhade, P., and Shirke, P. (2024). Federated learning for healthcare: a comprehensive review.\nEng. Proc.\n59:230. doi: 10.3390/engproc2023059230\nCrossref Full Text\n|\nGoogle Scholar\nEyben, F., Scherer, K. R., Schuller, B. W., Sundberg, J., Andr\u00e9, E., Busso, C., et al. (2015). The Geneva minimalistic acoustic parameter set (GeMAPS) for voice research and affective computing.\nIEEE Trans. Affect. Comput.\n7, 190-202. doi: 10.1109/TAFFC.2015.2457417\nCrossref Full Text\n|\nGoogle Scholar\nEyben, F, W\u00f6llmer, M, and Schuller, B. Opensmile: the munich versatile and fast open-source audio feature extractor. In Proceedings of the 18th ACM international conference on Multimedia; (2010).\nGoogle Scholar", "doc_items_refs": ["#/texts/545", "#/texts/546", "#/texts/547", "#/texts/548", "#/texts/549", "#/texts/550", "#/texts/551", "#/texts/552", "#/texts/553", "#/texts/554", "#/texts/555", "#/texts/556", "#/texts/557", "#/texts/558", "#/texts/559", "#/texts/560", "#/texts/561", "#/texts/562", "#/texts/563", "#/texts/564", "#/texts/565", "#/texts/566", "#/texts/567", "#/texts/568", "#/texts/569", "#/texts/570", "#/texts/571", "#/texts/572", "#/texts/573", "#/texts/574"], "page_nos": [], "uuid": "f1dd3bf8-8aae-4923-8ae6-72608f32003f"}
{"doc_id": "2025__Federated_learning_for_cognitive_impairment_detection_using_speech_data__W4414992495", "source_path": "<redacted:source_path>", "chunk_id": 26, "source_chunk_idxs": [33], "num_tokens": 432, "text": "Federated learning for cognitive impairment detection using speech data\nReferences\nGarc\u00eda Guti\u00e9rrez, F., Alegret, M., Marquie, M., Mu\u00f1oz, N., Ortega, G., Cano, A., et al. (2024). Unveiling the sound of the cognitive status: machine learning-based speech analysis in the Alzheimer's disease spectrum.\nAlzheimer's Res Ther\n16:2.\nGoogle Scholar\nGarc\u00eda Guti\u00e9rrez, F., Marquie, M., Mu\u00f1oz, N., Alegret, M., Cano, A., de Rojas, I., et al. (2023). Harnessing acoustic speech parameters to decipher amyloid status in individuals with mild cognitive impairment.\nFront. Neurosci.\n17:1221401. doi: 10.3389/fnins.2023.1221401\nCrossref Full Text\n|\nGoogle Scholar\nGMV. uTile. Welcome to information exchange 2.0. (2024) Available online at:\nhttps://www.gmv.com/en-es/products/cybersecurity/utile\n.\nGoogle Scholar\nHajjar, I., Okafor, M., Choi, J., Moore, E., Abrol, A., Calhoun, V., et al. (2023). Development of digital voice biomarkers and associations with cognition, cerebrospinal biomarkers, and neural representation in early Alzheimer's disease.\nAlzheimers Dement (N Y).\n15:e12393. doi: 10.1002/dad2.12393\nCrossref Full Text\n|\nGoogle Scholar\nHardy, S, Henecka, W, Ivey-Law, H, Nock, R, Patrini, G, and Smith, G (2017) Private federated learning on vertically partitioned data via entity resolution and additively homomorphic encryption. doi: 10.48550/arXiv.1711.10677\nCrossref Full Text\n|\nGoogle Scholar", "doc_items_refs": ["#/texts/575", "#/texts/576", "#/texts/577", "#/texts/578", "#/texts/579", "#/texts/580", "#/texts/581", "#/texts/582", "#/texts/583", "#/texts/584", "#/texts/585", "#/texts/586", "#/texts/587", "#/texts/588", "#/texts/589", "#/texts/590", "#/texts/591", "#/texts/592", "#/texts/593", "#/texts/594", "#/texts/595", "#/texts/596", "#/texts/597", "#/texts/598"], "page_nos": [], "uuid": "2594e137-7f65-4585-a6ce-e1ab116cae31"}
{"doc_id": "2025__Federated_learning_for_cognitive_impairment_detection_using_speech_data__W4414992495", "source_path": "<redacted:source_path>", "chunk_id": 27, "source_chunk_idxs": [34], "num_tokens": 456, "text": "Federated learning for cognitive impairment detection using speech data\nReferences\nJessen, F., Amariglio, R., Boxtel, M., Breteler, M., Ceccaldi, M., Ch\u00e9telat, G., et al. (2014). A conceptual framework for research on subjective cognitive decline in preclinical Alzheimer's disease.\nAlzheimers Dement.\n10, 844-852. doi: 10.1016/j.jalz.2014.01.001\nCrossref Full Text\n|\nGoogle Scholar\nKairouz, P, McMahan, HB, Avent, B, Bellet, A, Bennis, M, Bhagoji, AN, et al.\nAdvances and open problems in federated learning\n. Boston - Delft: Now Foundations and Trends. (2021).\nGoogle Scholar\nMateus, P., Yu, J., Garst, S., Harms, A., Cats, D., Bermejo, I., et al. (2023). Federated brainage estimation from MRI: a proof of concept.\nAlzheimers Dement.\n19. doi: 10.1002/alz.076747\nCrossref Full Text\n|\nGoogle Scholar\nMcKhann, G. M., Knopman, D. S., Chertkow, H., Hyman, B. T., Jack, C. R. Jr., Kawas, C. H., et al. (2011). The diagnosis of dementia due to Alzheimer's disease: recommendations from the National Institute on Aging-Alzheimer's association workgroups on diagnostic guidelines for Alzheimer's disease.\nAlzheimers Dement.\n7, 263-269. doi: 10.1016/j.jalz.2011.03.005\nPubMed Abstract\n|\nCrossref Full Text\n|\nGoogle Scholar\nMcMahan, H. Brendan, Moore, Eider, Ramage, Daniel, Hampson, Seth, and Ag\u00fcera y Arcas, Blaise. In Proceedings of the 20th International Conference on Artificial Intelligence and Statistics; (2017). p. 1273-1282.\nGoogle Scholar", "doc_items_refs": ["#/texts/599", "#/texts/600", "#/texts/601", "#/texts/602", "#/texts/603", "#/texts/604", "#/texts/605", "#/texts/606", "#/texts/607", "#/texts/608", "#/texts/609", "#/texts/610", "#/texts/611", "#/texts/612", "#/texts/613", "#/texts/614", "#/texts/615", "#/texts/616", "#/texts/617", "#/texts/618", "#/texts/619", "#/texts/620", "#/texts/621", "#/texts/622", "#/texts/623", "#/texts/624"], "page_nos": [], "uuid": "b06809eb-3920-487a-93e8-c8894233842c"}
{"doc_id": "2025__Federated_learning_for_cognitive_impairment_detection_using_speech_data__W4414992495", "source_path": "<redacted:source_path>", "chunk_id": 28, "source_chunk_idxs": [35], "num_tokens": 479, "text": "Federated learning for cognitive impairment detection using speech data\nReferences\nMeerza, SIA, Li, Z, Liu, L, Zhang, J, and Liu, J. Fair and privacy-preserving Alzheimer's disease diagnosis based on spontaneous speech analysis via federated learning. In 2022 44th Annual International Conference of the IEEE Engineering in Medicine &amp; Biology Society (EMBC); (2022) p. 1362-1365.\nGoogle Scholar\nPetersen, R. C. (2004). Mild cognitive impairment as a diagnostic entity.\nJ. Intern. Med.\n256, 183-194. doi: 10.1111/j.1365-2796.2004.01388.x\nPubMed Abstract\n|\nCrossref Full Text\n|\nGoogle Scholar\nQi, P., Chiaro, D., Guzzo, A., Ianni, M., Fortino, G., and Piccialli, F. (2023). Model aggregation techniques in federated learning: a comprehensive survey.\nFutur. Gener. Comput. Syst.\n150, 272-293. doi: 10.1016/j.future.2023.09.008\nCrossref Full Text\n|\nGoogle Scholar\nSharafeldeen, A., Keowen, J., and Shaffie, A. (2025). Machine learning approaches for speech-based Alzheimer's detection: a comprehensive survey.\nComputers\n14:36. doi: 10.3390/computers14020036\nCrossref Full Text\n|\nGoogle Scholar\nTeo, Z., Jin, L., Liu, N., Li, S., Miao, D., Zhang, X., et al. (2024). Federated machine learning in healthcare: a systematic review on clinical applications and technical architecture.\nCell Rep. Med.\n5:101481. doi: 10.1016/j.xcrm.2024.101481\nPubMed Abstract\n|\nCrossref Full Text\n|\nGoogle Scholar\nVasa, J, Thakkar, A, Bhavsar, D, and Patel, P. Guarding privacy in federated learning: exploring threat landscapes and countermeasures with case studies. In International conference on ICT for sustainable development; (2024). 221-231.\nGoogle Scholar", "doc_items_refs": ["#/texts/625", "#/texts/626", "#/texts/627", "#/texts/628", "#/texts/629", "#/texts/630", "#/texts/631", "#/texts/632", "#/texts/633", "#/texts/634", "#/texts/635", "#/texts/636", "#/texts/637", "#/texts/638", "#/texts/639", "#/texts/640", "#/texts/641", "#/texts/642", "#/texts/643", "#/texts/644", "#/texts/645", "#/texts/646", "#/texts/647", "#/texts/648", "#/texts/649", "#/texts/650", "#/texts/651", "#/texts/652", "#/texts/653", "#/texts/654", "#/texts/655", "#/texts/656"], "page_nos": [], "uuid": "e15c4bec-9ce4-42f6-9b5e-6ae059ce5c17"}
{"doc_id": "2025__Federated_learning_for_cognitive_impairment_detection_using_speech_data__W4414992495", "source_path": "<redacted:source_path>", "chunk_id": 29, "source_chunk_idxs": [36], "num_tokens": 400, "text": "Federated learning for cognitive impairment detection using speech data\nReferences\nWojtowytsch, S. (2021). Stochastic gradient descent with noise of machine learning type. Part I: discrete time analysis.\nJournal of Nonlinear Science\n. 33:45. doi: 10.1007/s00332-023-09903-3\nCrossref Full Text\n|\nGoogle Scholar\nWurtz, H. M., Manchester, M., Valteau, T., Hanson, H., Scipion, C., Federman, A., et al. (2025). Artificial intelligence as a tool for cognitive impairment screening: patient perspectives about benefits and limitations.\nAlzheimer's Dementia\n1:e70005. doi: 10.1002/bsa3.70005\nPubMed Abstract\n|\nCrossref Full Text\n|\nGoogle Scholar\nYeganeh, Y, Farshad, A, Navab, N, and Albarqouni, S. Inverse distance aggregation for federated learning with non-IID data. In Domain adaptation and representation transfer, and distributed and collaborative learning: Second MICCAI workshop, DART 2020, and first MICCAI workshop, DCL 2020, held in conjunction with MICCAI 2020, Lima, Peru, October 4-8, 2020, proceedings; (2020). p. 150-159.\nGoogle Scholar\nZhang, F., Kreuter, D., Chen, Y., Dittmer, S., Tull, S., Shadbahr, T., et al. (2024). Recent methodological advances in federated learning for healthcare.\nPatterns.\n5:101006. doi: 10.1016/j.patter.2024.101006\nCrossref Full Text\n|\nGoogle Scholar\nKeywords: deep learning, Alzheimer's disease, cognitive impairments, speech acoustics, federated learning", "doc_items_refs": ["#/texts/657", "#/texts/658", "#/texts/659", "#/texts/660", "#/texts/661", "#/texts/662", "#/texts/663", "#/texts/664", "#/texts/665", "#/texts/666", "#/texts/667", "#/texts/668", "#/texts/669", "#/texts/670", "#/texts/671", "#/texts/672", "#/texts/673", "#/texts/674", "#/texts/675", "#/texts/676", "#/texts/677", "#/texts/678", "#/texts/679"], "page_nos": [], "uuid": "b7afe052-1643-42b2-96d5-ca21c7b1904b"}
{"doc_id": "2025__Federated_learning_for_cognitive_impairment_detection_using_speech_data__W4414992495", "source_path": "<redacted:source_path>", "chunk_id": 30, "source_chunk_idxs": [37], "num_tokens": 482, "text": "Federated learning for cognitive impairment detection using speech data\nReferences\nCitation: Blazquez-Folch J, Limones Andrade M, Calm B, Au\u00f1\u00f3n Garc\u00eda JM, Alegret M, Mu\u00f1oz N, Cano A, Fern\u00e1ndez V, Garc\u00eda-Guti\u00e9rrez F, De Rojas I, Garc\u00eda-Gonz\u00e1lez P, Oliv\u00e9 C, Puerta R, Capdevila-Bayo M, Mu\u00f1oz-Morales \u00c1, Bay\u00f3n-Buj\u00e1n P, Miguel A, Montrreal L, Espinosa A, Sanz-Cartagena P, Rosende-Roca M, Zaldua C, Gabirondo P, Cantero-Fortiz Y, Gurruchaga MJ, Tarraga L, Boada M, Ruiz A, Marqui\u00e9 M and Valero S (2025) Federated learning for cognitive impairment detection using speech data.\nFront. Artif. Intell\n. 8:1662859. doi: 10.3389/frai.2025.1662859\nReceived: 09 July 2025; Accepted: 24 September 2025; Published: 09 October 2025.\nEdited by:\nChao Ma\n, Southeast University, China\nReviewed by:\nWenshan Sun\n, Nanjing Medical University, China\nSanjaykumar Patel\n, University of Bridgeport, United States\nCopyright \u00a9 2025 Blazquez-Folch, Limones Andrade, Calm, Au\u00f1\u00f3n Garc\u00eda, Alegret, Mu\u00f1oz, Cano, Fern\u00e1ndez, Garc\u00eda-Guti\u00e9rrez, De Rojas, Garc\u00eda-Gonz\u00e1lez, Oliv\u00e9, Puerta, Capdevila-Bayo, Mu\u00f1oz-Morales, Bay\u00f3n-Buj\u00e1n, Miguel, Montrreal, Espinosa, Sanz-Cartagena, Rosende-Roca, Zaldua, Gabirondo, Cantero-Fortiz, Gurruchaga, Tarraga, Boada, Ruiz, Marqui\u00e9 and Valero. This is an open-access article distributed under the terms of the\nCreative Commons Attribution License (CC BY)\n. The use, distribution or reproduction in other forums is permitted, provided the original author(s) and the copyright owner(s) are credited and that the original publication in this journal is cited, in accordance with accepted academic practice. No use, distribution or reproduction is permitted which does not comply with these terms.", "doc_items_refs": ["#/texts/680", "#/texts/681", "#/texts/682", "#/texts/683", "#/texts/684", "#/texts/685", "#/texts/686", "#/texts/687", "#/texts/688", "#/texts/689", "#/texts/690", "#/texts/691", "#/texts/692", "#/texts/693", "#/texts/694"], "page_nos": [], "uuid": "31322aec-89f5-45fb-b28b-5c916b65505c"}
{"doc_id": "2025__Federated_learning_for_cognitive_impairment_detection_using_speech_data__W4414992495", "source_path": "<redacted:source_path>", "chunk_id": 31, "source_chunk_idxs": [38, 39], "num_tokens": 359, "text": "Federated learning for cognitive impairment detection using speech data\nReferences\n*Correspondence: Sergi Valero, c3ZhbGVyb0BmdW5kYWNpb2FjZS5vcmc=\n\u2020\nThese authors have contributed equally to this work\nDisclaimer: All claims expressed in this article are solely those of the authors and do not necessarily represent those of their affiliated organizations, or those of the publisher, the editors and the reviewers. Any product that may be evaluated in this article or claim that may be made by its manufacturer is not guaranteed or endorsed by the publisher.\nDownload article\n- Download PDF\n- ReadCube\n- epub\n- XML\nShare on\nExport citation\n- EndNote\n- Reference Manager\n- Simple Text file\n- BibTex\n719 Total views 55 Downloads Citation numbers are available from Dimensions\nView article impact\nView altmetric score\nShare on\nEdited by\nC M Chao  Ma\nReviewed by\nS P Sanjaykumar  Patel\nW S Wenshan  Sun\nTable of contents\n- Abstract\n- 1 Introduction\n- 2 Methods\n- 3 Results\n- 4 Discussions and conclusions\n- Data availability statement\n- Ethics statement\n- Author contributions\n- Funding\n- Acknowledgments\n- Conflict of interest\n- Generative AI statement\n- Publisher's note\n- Supplementary material\n- References\nExport citation\n- EndNote\n- Reference Manager\n- Simple Text file\n- BibTex\nCheck for updates\nFrontiers' impact\n\nFederated learning for cognitive impairment detection using speech data\nArticles published with Frontiers have received 12 million total citations\nYour research is the real superpower - learn how we maximise its impact through our leading community journals\nExplore our impact metrics\nSupplementary Material\nDownload article\nDownload\n- Download PDF\n- ReadCube\n- epub\n- XML\n- Guidelines\n- Explore\n- Outreach\n- Connect\nFollow us\n\u00a9 2025 Frontiers Media S.A. All rights reserved\nPrivacy policy\n|\nTerms and conditions", "doc_items_refs": ["#/texts/695", "#/texts/696", "#/texts/697", "#/texts/698", "#/texts/699", "#/texts/700", "#/texts/701", "#/texts/702", "#/texts/703", "#/texts/704", "#/texts/705", "#/texts/706", "#/texts/707", "#/texts/708", "#/texts/709", "#/texts/710", "#/texts/711", "#/texts/712", "#/texts/713", "#/texts/714", "#/texts/715", "#/texts/716", "#/texts/717", "#/texts/718", "#/texts/719", "#/texts/720", "#/texts/721", "#/texts/722", "#/texts/723", "#/texts/724", "#/texts/725", "#/texts/726", "#/texts/727", "#/texts/728", "#/texts/729", "#/texts/730", "#/texts/731", "#/texts/732", "#/texts/733", "#/texts/734", "#/texts/735", "#/texts/736", "#/texts/737", "#/texts/738", "#/texts/739", "#/texts/740", "#/texts/741", "#/texts/743", "#/texts/744", "#/texts/745", "#/texts/746", "#/texts/747", "#/texts/748", "#/texts/749", "#/texts/750", "#/texts/751", "#/texts/752", "#/texts/753", "#/texts/754", "#/texts/755", "#/texts/756", "#/texts/757", "#/texts/758", "#/texts/759", "#/texts/760"], "page_nos": [], "uuid": "071e7e3e-c4ad-450e-99f7-c3c9c665ed3d"}
