name: Documentation Generation and Deployment

on:
    push:
        branches: [main]
        paths:
            - "docs/**"
            - "src/**"
            - ".github/workflows/docs-generation.yml"
    release:
        types: [published]
    workflow_dispatch:
        inputs:
            reason:
                description: "Reason for manual documentation generation"
                required: true
                default: "Manual documentation update"

jobs:
    generate-and-deploy-docs:
        runs-on: ubuntu-latest
        permissions:
            contents: write

        steps:
            - name: Checkout repository
              uses: actions/checkout@v4
              with:
                  fetch-depth: 0

            - name: Set up Python
              uses: actions/setup-python@v4
              with:
                  python-version: "3.13"

            - name: Install system dependencies
              run: |
                  sudo apt-get update
                  sudo apt-get install -y python3-sphinx

            - name: Install Python dependencies
              run: |
                  python -m pip install --upgrade pip
                  pip install pyyaml aiohttp

            - name: Make scripts executable
              run: chmod +x docs/scripts/*.py

            - name: Generate API documentation
              run: |
                  python docs/scripts/generate_api_docs.py

            - name: Validate documentation
              run: |
                  python docs/scripts/validate_docs.py

            - name: Check for broken links
              run: |
                  python docs/scripts/check_links.py --quick --timeout 5

            - name: Build Sphinx documentation
              run: |
                  python docs/scripts/build_docs.py --format html

            - name: Generate documentation index
              run: |
                  # Create a comprehensive documentation index
                  python -c "
                  from pathlib import Path
                  import os

                  docs_dir = Path('docs')
                  index_content = []

                  index_content.append('# Documentation Index')
                  index_content.append('')
                  index_content.append('This page provides a complete index of all documentation files in the DocsToKG project.')
                  index_content.append('')

                  # Walk through all documentation directories
                  for root, dirs, files in os.walk(docs_dir):
                      # Skip build directories
                      if any(skip in root for skip in ['build', '__pycache__', '.git']):
                          continue

                      rel_root = Path(root).relative_to(docs_dir)
                      if rel_root == Path('.'):
                          continue

                      # Add section header
                      if files and any(f.endswith('.md') for f in files):
                          section_name = str(rel_root).replace('/', ' ‚Ä∫ ')
                          index_content.append(f'## {section_name}')
                          index_content.append('')

                          for file in sorted(files):
                              if file.endswith('.md'):
                                  file_path = Path(root) / file
                                  rel_path = file_path.relative_to(docs_dir)
                                  index_content.append(f'- [{file}]({rel_path})')

                          index_content.append('')

                  # Write index file
                  index_file = docs_dir / 'documentation_index.md'
                  with open(index_file, 'w') as f:
                      f.write('\n'.join(index_content))

                  print(f'üìã Generated documentation index with {len(index_content)} lines')
                  "

            - name: Generate documentation statistics
              run: |
                  python -c "
                  from pathlib import Path
                  import json

                  docs_dir = Path('docs')

                  # Count different types of files
                  stats = {
                      'total_files': 0,
                      'markdown_files': 0,
                      'python_scripts': 0,
                      'template_files': 0,
                      'total_lines': 0,
                      'sections': {}
                  }

                  for file_path in docs_dir.rglob('*'):
                      if file_path.is_file() and not any(skip in str(file_path) for skip in ['build', '__pycache__', '.git']):
                          stats['total_files'] += 1

                          if file_path.suffix == '.md':
                              stats['markdown_files'] += 1
                              try:
                                  with open(file_path, 'r') as f:
                                      lines = f.readlines()
                                      stats['total_lines'] += len(lines)

                                      # Count sections by directory
                                      rel_path = str(file_path.relative_to(docs_dir))
                                      section = rel_path.split('/')[0] if '/' in rel_path else 'root'
                                      if section not in stats['sections']:
                                          stats['sections'][section] = 0
                                      stats['sections'][section] += 1
                              except:
                                  pass

                          elif file_path.suffix == '.py':
                              stats['python_scripts'] += 1

                          elif 'templates' in str(file_path):
                              stats['template_files'] += 1

                  # Save stats
                  stats_file = docs_dir / 'documentation_stats.json'
                  with open(stats_file, 'w') as f:
                      json.dump(stats, f, indent=2)

                  print('üìä Documentation Statistics:')
                  for key, value in stats.items():
                      if isinstance(value, dict):
                          print(f'  {key}:')
                          for subkey, subvalue in value.items():
                              print(f'    {subkey}: {subvalue}')
                      else:
                          print(f'  {key}: {value}')
                  "

            - name: Deploy to GitHub Pages
              if: github.event_name == 'release' || github.event_name == 'workflow_dispatch'
              uses: peaceiris/actions-gh-pages@v3
              with:
                  github_token: ${{ secrets.GITHUB_TOKEN }}
                  publish_dir: ./docs/html
                  publish_branch: gh-pages
                  cname: docs.docstokg.dev # Optional: set custom domain

            - name: Upload documentation artifacts
              if: always()
              uses: actions/upload-artifact@v4
              with:
                  name: documentation-artifacts
                  path: |
                      docs/html/
                      docs/documentation_index.md
                      docs/documentation_stats.json
                      docs/link_check_report.md

            - name: Comment on PR with documentation status
              if: github.event_name == 'pull_request'
              uses: actions/github-script@v6
              with:
                  script: |
                      const fs = require('fs');

                      let comment = '## üìö Documentation Check Results\n\n';

                      try {
                        const stats = JSON.parse(fs.readFileSync('docs/documentation_stats.json'));
                        comment += `‚úÖ **Documentation Status:** ${stats.markdown_files} files, ${stats.total_lines} lines\n\n`;

                        const linkReport = fs.readFileSync('docs/link_check_report.md', 'utf8');
                        const brokenLinksMatch = linkReport.match(/Broken Links: (\d+)/);
                        if (brokenLinksMatch) {
                          const brokenCount = parseInt(brokenLinksMatch[1]);
                          comment += `üîó **Links:** ${brokenCount === 0 ? 'All links working ‚úÖ' : `${brokenCount} broken links found ‚ö†Ô∏è`}\n\n`;
                        }

                        comment += 'üìã **Generated Files:**\n';
                        comment += '- API documentation updated\n';
                        comment += '- HTML documentation built\n';
                        comment += '- Link validation completed\n\n';

                        comment += 'üîç For detailed reports, check the workflow artifacts.';
                      } catch (error) {
                        comment += '‚ö†Ô∏è Could not generate detailed report\n\n';
                        comment += 'Please check the workflow logs for details.';
                      }

                      github.rest.issues.createComment({
                        issue_number: context.issue.number,
                        owner: context.repo.owner,
                        repo: context.repo.repo,
                        body: comment
                      });
